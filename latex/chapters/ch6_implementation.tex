% !TeX root = ../main.tex
\chapter{Implementation}
\label{ch:implementation}

After defining functional and non-functional requirements, the two applications can be implemented. The implementation phase will be detailed in this chapter. After describing the utilized technologies, the \glspl{contract-test} executed on both applications are outlined. Next, implementation details of \gls{crud} and \gls{es}-\gls{cqrs} are given. Finally, the load tests are presented.

\section{Endpoints}
\label{sec:endpoints}

Table \autoref{table:endpoints} presents a feature matrix, mapping \acrshort{http} endpoints to their functionality. As this thesis focuses not on the functionality of an application, but instead an architectural comparison, only the endpoints which will later be load-tested are listed.

\begin{table}[htp!]
    \small
    \centering
    \begin{tabularx}{\linewidth}{lXc}
        \toprule
        \textbf{Endpoint}                     & \textbf{Description}                                        & \textbf{Response} \\ \midrule
        \texttt{GET /lectures}                & Returns all lectures a student is enrolled or waitlisted in & 200               \\
        \addlinespace
        \texttt{GET /lectures/all}            & Returns details for all lectures                            & 200               \\
        \addlinespace
        \texttt{POST /courses}                & Creates a course                                            & 201               \\
        \addlinespace
        \texttt{POST /lectures/\{id\}/enroll} & Enroll to a lecture                                         & 201               \\
        \addlinespace
        \texttt{GET /stats/credits}           & Returns a student's current credits                         & 201               \\
        \addlinespace
        \texttt{GET /stats/grades/history}    & Returns the grade history for an assessment                 & 201               \\
        \bottomrule
    \end{tabularx}
    \caption{Endpoints which will be load-tested}
    \label{table:endpoints}
\end{table}

\section{Technologies}
\label{sec:technologies}

This section describes all technologies used for the implementation and evaluation of the two applications.

\subsection{SpringBoot}

SpringBoot\footnote{\url{https://spring.io/projects/spring-boot}} is an open-source, opinionated framework for developing enterprise Java applications. It is based on Spring Framework,\footnote{\url{https://spring.io/projects/spring-framework}} which is a platform aiming to make Java development "quicker, easier, and safer for everybody"~\cite{broadcom_inc_why_2026}. At Spring Framework's core is the Inversion of Control (IoC) container. The objects managed by this container are referred to as \textit{Beans}. While the term originates from the Java Beans specification, a standard for creating reusable software components developed by \textcite{sun_microsystems_javabeans_1997}, Spring extends this concept by taking full responsibility for the lifecycle and configuration of these objects~\cite[Chapter 1.1]{walls_spring_2016}. Instead of a developer manually instantiating classes using the \texttt{new} operator, the container "injects" required dependencies at runtime. This process is known as Dependency Injection~\cite[Chapter~1]{deinum_spring_2023}. Spring offers support for several programming paradigms: reactive, event-driven, microservices and serverless~\cite{broadcom_inc_why_2026}.

SpringBoot builds on top of the Spring platform by applying a "convention-over-configuration" approach, intended to minimize the need for configuration. In a 2023 survey by JetBrains, SpringBoot was the most popular choice of web framework~\cite{jetbrains_java_2023}.

SpringBoot starters are specialized dependency descriptors designed to simplify dependency management by aggregating commonly used libraries into feature-defined packages. Rather than requiring developers to manually identify and maintain a list of individual group IDs, artifact IDs, and compatible version numbers for every necessary library, starters use transitive dependency resolution to pull in all required components under a single entry. To quickly bootstrap a web application, a developer can simply add the \javaname{spring-boot-starter-web} dependency to their Maven or Gradle build file. By requesting this specific functionality, Spring Boot automatically includes essential dependencies such as Spring MVC, Jackson for JSON processing, and an embedded Tomcat server, ensuring that all included libraries have been tested together for compatibility. This approach shifts the developer's focus from managing individual JAR files to simply defining the high-level capabilities the application requires, minimizing configuration overhead and reducing risk of version mismatches~\cite[Chapter~1.1.2]{walls_spring_2016}.

\subsection{PostgreSQL}
\label{sec:postgresql}

PostgreSQL\footnote{\url{https://www.postgresql.org/}} is an open-source relational database system which has been in active development for over 35 years. Thanks to its reliability, robustness and performance, it has a strong earned reputation~\cite{postgresql_global_development_group_postgresql_2026}. PostgreSQL is designed for a wide range of workloads and can handle many tasks thanks to its extensibility and large suite of extensions, such as the popular PostGIS extension for storing and querying geospatial data~\cite{postgis_psc_postgis_2023}.

\subsection{JPA}
\label{sec:jpa}

\gls{jpa}\footnote{\url{https://jakarta.ee/specifications/persistence/}}, formerly \emph{Java Persistence \gls{api}} is a Java specification which provides a mechanism for managing persistence and object-relational mapping. \glspl{orm} act as a mapper between the relational world of SQL databases and the object-oriented world of Java~\cite[Chapter~1]{bauer_java_2016}.

Instead of writing SQL to create the database schema, entities can be described using special Java classes, supported by annotations, which can be mapped to an SQL schema. Using an \keyw{EntityManager}, these entities can be persisted and queried~\cite[Chapter~3]{bauer_java_2016}.

When using \acrshort{jpa} with SpringBoot by including the \javaname{spring-boot-starter-data-jpa} dependency, \emph{Hibernate}\footnote{\url{https://hibernate.org/orm/}} is used as implementation of the \acrshort{jpa} standard~\cite[Chapter~1]{bauer_java_2016}.

\subsection{Hibernate Envers}
\label{sec:envers}

Envers\footnote{\url{https://hibernate.org/orm/envers/}} is a Hibernate project designed for audit logging and versioning of historic data. When using Envers, a copy of data (a "revision") is stored in specific revision tables managed by Envers~\cite[Chapter~13.3]{bauer_java_2016}.

Envers offers an API, primarily accessed through the \keyw{AuditReader}, to query historic versions of data~\cite[Chapter~13.3]{bauer_java_2016}.

To use Hibernate Envers, the \javaname{org.hibernate.orm:hibernate-envers} dependency must be added to the project's classpath.

\subsection{Jackson}

Jackson\footnote{\url{https://github.com/FasterXML/jackson}} is a high-performance, feature-rich \acrshort{json} processing library for Java. It is the default \acrshort{json} library used within the Spring Boot ecosystem. Its primary purpose is to provide a seamless bridge between Java objects and JSON data through three main processing models: the Streaming API for incremental parsing, the Tree Model for a flexible node-based representation, and the most commonly used Data Binding module. This data binding capability allows developers to automatically convert (\emph{marshal}) Java \acrshortpl{pojo} into JSON and vice versa (\emph{unmarshal}) with minimal configuration. Beyond its speed and efficiency, Jackson is highly extensible, offering modules to handle complex Java types like Java 8 Date/Time and Optional classes. Jackson also supports various other data formats such as XML, YAML and CSV~\cite{oracle_jackson_nodate, fasterxml_jackson_2025}.

\subsection{Axon}
\label{sec:axon}

Axon Framework\footnote{\url{https://www.axoniq.io/framework}} is an open-source Java framework for building event-driven applications. Following the \acrshort{cqrs} and \acrlong{es} pattern, Commands, Events and Queries are the three core message types any Axon application is centered around. Commands are used to describe an intent to change the application's state. Events communicate a change that happened in the application. Queries are used to request information from the application~\cite{axoniq_messaging_2025}.

Axon also supports \acrlong{ddd} by providing tools to manage entities and domain logic~\cite{axoniq_introduction_2025,axoniq_messaging_2025}.

Axon Server\footnote{\url{https://www.axoniq.io/server}} is a platform designed specifically for event-driven systems. It functions as both a high-performance Event Store and a dedicated Message Router for commands, queries, and events. By bundling these responsibilities into a single service, Axon Server replaces the need for separate infrastructures such as a relational database for events and a message broker like Kafka or RabbitMQ for communication. Axon Server is designed to seamlessly integrate with Axon Framework. When using the Axon Server Connector, the application automatically finds and connects to the Axon Server. It is then possible to use the Axon server without further configuration~\cite{axoniq_introduction_2025-1,axoniq_axon_2025}.

This subsection describes core concepts of Axon. Diagrams illustrating the data flow through an application built with Axon are available in \autoref{sec:es-cqrs-tracing-request-flow}.

\subsubsection*{Command Dispatching}
Command dispatching is the starting point for handling a command message in Axon. Axon handles commands by routing them to the appropriate command handler. The command dispatching infrastructure can be interacted with using the low-level \keyw{CommandBus} and a more convenient \keyw{CommandGateway}~\cite{axoniq_command_2025}.

\keyw{CommandBus} is the infrastructure mechanism responsible for finding and invoking the correct command handler. At most one handler is invoked for each command; if no handler is found, an exception is thrown~\cite{axoniq_command_2025}.

% Using \keyw{CommandGateway} simplifies command dispatching by hiding the manual creation of \keyw{CommandMessages}. The gateway offers two main methods for synchronous and asynchronous patterns. The \keyw{send} method returns a \keyw{CompletableFuture}, which is an asynchronous mechanism in Java. If the thread needs to wait for the command result, the \keyw{sendAndWait} method can be used.

In general, command handling functions return \keyw{null} if handling was successful, except for command handlers which \emph{create} Aggregates. These return the Aggregate identifier. Otherwise, a \keyw{CommandExecutionException} is propagated to the caller. While returning values from a command handler is not forbidden, it is used sparsely as it contradicts with \gls{cqrs} semantics~\cite{axoniq_command_2025,axoniq_infrastructure_2025}.

\subsubsection*{Query Handling}
Axon dispatches Queries through its messaging infrastructure. Just like the command infrastructure, Axon offers a low-level \keyw{QueryBus} which requires manual query message creation and a more high-level \keyw{QueryGateway}. When no query handler is found, an exception is thrown~\cite{axoniq_query_2025}.

The \keyw{QueryGateway} includes different dispatching methods. For regular "point-to-point" queries, the \keyw{query} method can be used. For large result sets, streaming queries should be used. All query methods are asynchronous by nature and return Java's \keyw{CompletableFuture}~\cite{axoniq_query_2025}.

Subscription Queries provide an initial result and continuous updates as data changes. These queries work well with reactive programming. By using a subscription query inside a web controller, a synchronous interface can be provided to clients, while keeping the internal command and event handling process asynchronous. While this approach does provide the desired synchronous user experience, it has the downside of coupling the client to the event processing flow. Alternatively, developers might employ WebSockets or other client-side notification mechanisms to inform the user about the result of their action asynchronously, after the initial request was accepted~\cite{axoniq_query_2025}.

\subsubsection*{Aggregates}
\label{sec:aggregates}
Aggregates are a core concept of \gls{ddd}, which was described in \autoref{sec:ddd}. They define command handlers using the \keyw{@CommandHandler} annotation. These handlers receive commands and decide whether they are valid according to domain rules. If a command is accepted, the aggregate emits one or more domain events describing \emph{what} happened. Command handlers are responsible only for decision-making; they must not directly mutate the aggregate’s state. Instead, all state changes must occur as a result of applying events~\cite{axoniq_aggregates_2025}.

Every Aggregate is annotated with \keyw{@Aggregate} and must declare exactly one field annotated with \keyw{@AggregateIdentifier}. This identifier uniquely identifies the Aggregate instance. Axon uses it to route incoming commands to the correct Aggregate and to load the corresponding event stream when rebuilding Aggregate state~\cite{axoniq_aggregates_2025}.

By default, Axon uses Event-sourced Aggregates. This means that Aggregates are not persisted as a simple snapshot of their fields. Instead, their current state is reconstructed by replaying all previously stored events. Methods annotated with \keyw{@EventSourcingHandler} are called by Axon during this replay process to update the aggregate’s internal state based on event data. Since events represent facts that already occurred, event sourcing handlers must not contain business logic or make decisions~\cite{axoniq_aggregates_2025}.

Axon also supports multi-entity Aggregates, where an Aggregate may contain child entities that participate in command handling. Such entities are registered using \keyw{@AggregateMember}, and each entity must define a unique identifier annotated with \keyw{@EntityId}. Based on this identifier, Axon is able to route commands to the correct entity instance within the Aggregate~\cite{axoniq_multi-entity_2025}.

\subsubsection*{External Command Handlers}
\label{sec:external-command-handlers}
Often, command handling functions are placed directly inside the Aggregate. However, this is not required and in some cases it may not be desirable or possible to directly route a command to an Aggregate. Thus, any object can be used as a command handler by including methods annotated with \keyw{@CommandHandler}. One instance of this command handling object will be responsible for handling \emph{all} commands of the command types it declares in its methods~\cite{axoniq_command_2025-1}.

In these external command handlers, Aggregates can be loaded manually from Axon's repositories using the Aggregate's ID. Afterward, the \keyw{execute} function can be used to execute commands on the loaded Aggregate~\cite{axoniq_command_2025-1}.

\subsubsection*{Events}
\label{sec:axon-events}

Event handlers are methods annotated with \keyw{@EventHandler} which react to occurrences within the app by handling Axon's event messages. Each event handler specifies the types of events it is interested in. When no handler for a given event type exists in the application, the event is ignored~\cite{axoniq_event_2025}.

Axon's \keyw{@EventBus} is the infrastructure mechanism dispatching events to the subscribed event handlers. Event stores offer these functionalities and additionally persist and retrieve published events~\cite{axoniq_event_2025-1}.

Event processors take care of the technical part aspects of event processing. Axon's \keyw{EventBus} implementations support both subscribing and tracking event processors~\cite{axoniq_event_2025-1}. Subscribing event processors subscribe to a message source, which delivers (pushes) events to the processor. The event is then processed in the same thread that published the event. This makes subscribing event processors suitable for real-time updates of models. However, they can only be used to receive current events and do not support event replay. Additionally, as they run on the same thread, they can not be parallelized~\cite{axoniq_subscribing_2025}.

Tracking event processors, which a type of streaming event processors, read (pull) events to be processed from an event source. They run decoupled from the publishing thread, making them parallelizable. These event processors use tracking tokens track their position in the event stream. Tracking tokens can be reset and events can be replayed and reprocessed. Tracking event processors are the default in Axon and recommended for most ES-CQRS use cases~\cite{axoniq_streaming_2025}.

\subsubsection*{Set-based Validation}
\label{sec:set-based-validation}
When receiving a command, Aggregates handle it by validating their internal state inside command handlers and either rejecting the command or publishing an event. However, validation across a set of Aggregates, called "set-based validation", is not possible inside a single Aggregate. A business requirement like "Usernames must be unique" can only be implemented using set-based validation, as the entire set of Aggregates must be inspected before making a decision.

Set-based implementation in Axon can be implemented using \emph{lookup tables}. This approach utilizes a dedicated command-side projection, often referred to as a lookup projector, to maintain a specialized view of the system state. While projectors are typically associated with the read-side of a \acrshort{cqrs} architecture, a lookup projector is specifically designed to support the command side. It maintains an optimized and consistent dataset, such as a registry of unique IDs, which can be queried during the validation phase of a command~\cite{ceelie_set_2020}.

To ensure that this lookup table remains synchronized and provides the necessary consistency for validation, Axon employs subscribing event processors, which are described in \autoref{sec:axon-events}. Unlike tracking event processors which operate asynchronously and introduce eventual consistency, subscribing event processors execute within the same thread and transaction as the event publication. This mechanism ensures that the lookup table is updated immediately after an event is applied to the Aggregate. Consequently, if the update to the lookup table fails due to a constraint violation or database error, the entire transaction is rolled back, preventing the system from reaching an inconsistent state~\cite{axoniq_subscribing_2025,axoniq_event_2025-1}.

In practice, this validation logic is often encapsulated within a domain service or a validator interface that is injected directly into the Aggregate's command handler. This service interacts with the lookup table repository to verify global invariants before the Aggregate state is modified. By separating the lookup logic from the read-model, the system avoids the latency of eventual consistency while maintaining the architectural integrity of the Aggregate as a boundary for consistency. This pattern helps to enforce validation across individual aggregates and allows for global state verification~\cite{ceelie_set_2020}.

\subsubsection*{Sagas}
\label{sec:sagas}

In Axon, Sagas are long-running, stateful event handlers which not just react to events, but instead manage and coordinate business transactions. For each transaction being managed, one instance of a Saga exists. A Saga, which is a class annotated with \keyw{@Saga} has a lifecycle that is started by a specific event when a method annotated with \keyw{@StartSaga} is executed. The lifecycle may be ended when a method annotated with \keyw{@EndSaga} is executed; or conditionally using \keyw{SagaLifecycle.end()}. A Saga usually has a clear starting point, but may have many different ways for it to end. Each event handling method in a Saga must additionally have the \keyw{@SagaEventHandler} annotation~\cite{axoniq_saga_2025}.

The way Sagas manage business transactions is by sending commands upon receiving events. They can be used when workflows across several aggregates should be implemented; or to handle long-running processes that may span over any amount of time~\cite{axoniq_saga_2025}. For example, the lifecycle of an order, from being processed, to being shipped and paid, is a process that usually takes multiple days. A use case like this is typically implemented using Sagas.

A Saga is associated with one or more association values, which are key-value pairs used to route events to the correct Saga instance. A \keyw{@StartSaga} method together with the \keyw{@SagaEventHandler(associationProperty="aggregateId")} automatically associates the Saga with that identifier. Additional associations can be made programmatically, by calling \keyw{SagaLifecycle.associateWith()}. Any matching events are then routed to the Saga~\cite{axoniq_saga_2025-1}.

\subsection{SpringBoot Actuator}
\label{sec:actuator}

Spring Boot Actuator\footnote{\url{https://docs.spring.io/spring-boot/reference/actuator/index.html}} is a tool designed to help monitor and manage Spring Boot applications running in a production environment. It provides several built-in features that allow developers to check the status of the application, gather performance data, and track \gls{http} requests. These features can be accessed using either \gls{http} or \acrshort{jmx} (\acrlong{jmx}), which is a standard Java management technology. By using Actuator, developers can quickly see if an application is running correctly without the need to write custom monitoring code~\cite{broadcom_inc_production-ready_2026,broadcom_inc_metrics_2026}.

The most common way to use Actuator is through its "endpoints", which are specific web addresses that provide different types of information. For example, the health endpoint shows whether the application and its connected services, like databases, are functioning correctly, while the metrics endpoint displays detailed data on memory and CPU usage. Beyond the standard options, developers can also create their own custom endpoints or connect the data to external monitoring software to visualize how an application is performing over time~\cite{broadcom_inc_endpoints_2026}.

Actuator can be enabled in a Spring Boot project by including the \javaname{spring-boot-starter-actuator} dependency~\cite{broadcom_inc_enabling_2026}.

\subsection{Prometheus}

Prometheus\footnote{\url{https://prometheus.io/docs/introduction/overview/}} is an open-source systems monitoring toolkit that was originally developed at SoundCloud and is now a project of the Cloud Native Computing Foundation. It is primarily used for collecting and storing multidimensional metrics as time-series data, meaning information is recorded with a timestamp and optional key-value pairs called labels. The system is designed for reliability and is capable of scraping data from instrumented jobs and web servers, storing it in a local time-series database, and triggering alerts based on predefined rules when specific thresholds are met. Through its powerful functional query language, PromQL, developers can aggregate and visualize performance data~\cite{prometheus_authors_prometheus_2026,prometheus-overview-2026}.

To collect and export \hyperref[sec:actuator]{Actuator} metrics specifically for Prometheus, the \javaname{micrometer-registry-prometheus} dependency must be included in the classpath~\cite{vmware_inc_micrometer_nodate}. Access to the metrics is granted by including "prometheus" in the list of exposed web endpoints within the application's configuration properties. Once these components are in place, the metrics are automatically formatted for consumption and can be scraped by a Prometheus server~\cite{broadcom_inc_metrics_2026}.

\subsection{Docker}

\gls{docker}\footnote{\url{https://docs.docker.com/}} is a platform used for developing and deploying applications. It is designed to separate software from the underlying infrastructure, allowing for faster delivery and consistent environments.

\gls{docker}'s capabilities are centered around the use of containers, which are lightweight and isolated environments. Each container is packaged with all necessary dependencies required for an application to run, ensuring it operates independently of the host system. These workloads can be executed across different environments, such as local computers, data centers, or cloud providers, ensuring high portability~\cite{what-is-docker}.

A \gls{dockerfile} is a text-based document containing a series of instructions for assembling a Docker image. Each command in this file results in the creation of a layer in the image, making the final template efficient and fast to rebuild. These images serve as read-only blueprints from which runnable instances, or containers, are created~\cite{writing-a-dockerfile}.

Docker Compose is a tool used to define and manage applications consisting of multiple containers. A single configuration file is used to specify the services, networks, and volumes required for the entire application stack. The lifecycle of complex applications can be managed with this tool, enabling all associated services to be started, stopped, and coordinated with a single command~\cite{what-is-docker-compose}.

\subsection{k6}
\label{sec:k6}

Grafana k6\footnote{\url{https://grafana.com/docs/k6/latest/}} is an open-source performance testing tool designed to evaluate the reliability and performance of a system. It simulates various traffic patterns, such as constant load, sudden stress spikes, and long-term soak tests, to identify slow response times and system failures during development and continuous integration. Metrics are collected during execution and can be visualized through platforms like Grafana or exported to various data backends for detailed reporting~\cite{k6-overview}.

k6 allows tests to be written in JavaScript, making it accessible and easy to integrate into existing codebases. Every k6 test follows a common structure. The main component is a function that contains the core logic of the test. This function should be the default export of the JavaScript file. It is executed concurrently for each \acrlong{VU} (\acrshort{VU}), which act as independent execution threads to repeatedly apply the test logic. The tests can be enhanced using k6's lifecycle functions, such as a setup function, which is executed only once and may be utilized to insert seed data into the system. The test execution can be configured using an "options" object, where \acrshortpl{VU}, test duration and performance thresholds can be set~\cite{k6-write-your-first-test}.

\section{Contract Test Implementation}
\label{sec:contract-test-implementation}

To ensure the implementations adhere to the contract, a test suite is implemented in a separate module called \javaname{test-suite}\footnote{\javaname{test-suite/src/test/java/karsch.lukas}}, according to  \autoref{sec:contract}. The test classes use the \texttt{JUnit 5}\footnote{\url{https://docs.junit.org/5.14.3/overview.html}} testing framework and \texttt{REST Assured}\footnote{\url{https://rest-assured.io/}} to send and assert \gls{http} requests. The test classes are abstract and must be extended by both application to add implementation-specific functionality, such as teardown and seeding functions.

Necessary infrastructure for these tests is spun up by the subclasses using \glspl{testcontainer}\footnote{\url{https://testcontainers.com/}}. \glspl{testcontainer} is a way to declare infrastructure dependencies as code and is an open-source library available for many programming languages~\cite{testcontainers-homepage}.

\section{Shared Base Module}
\label{sec:shared-base-module}

The \texttt{api}\footnote{\javaname{api/src/main/java/karsch.lukas}} module serves as base module for both implementations. This module defines \glspl{dto}, which implemented using Java records, and controller interfaces exposing these record classes as part of their \gls{api}. These interfaces are then implemented by each application. Additionally, the base \texttt{api} module contains utilities and shared logic, for example \hyperref[sec:actuator]{Actuator} endpoints to control the application's internal clock.\footnote{\javaname{api/src/main/java/karsch.lukas.time.}\keyw{DateTimeActuatorEndpoints}}

\section{Authentication and Authorization}
\label{sec:authentication-authorization}

Instead of implementing real authentication using a technology like Spring Security\footnote{\url{https://spring.io/projects/spring-security}}, a simple header-based mechanism was used to simulate an authenticated state. This approach relies on a custom \gls{http} header to attach session information to requests.

This mechanism consists of two main components: a request-scoped \keyw{RequestContext}\footnote{\javaname{api/src/main/java/karsch.lukas.context.RequestContext}} bean that acts as a container for user data throughout the lifecycle of a single \gls{http} request; and a custom \keyw{UserFilter}\footnote{\javaname{api/src/main/java/karsch.lukas.context.UserFilter}} that intercepts incoming requests, parses the header, and populates the context.

The filter expects a header named \texttt{customAuth} with the format \texttt{<type>\_<uuid>}. The \keyw{type} and \keyw{uuid} are extracted from the header and set in the \keyw{RequestContext}.

This solution removes the additional implementation complexity of cryptographically secure authentication while allowing for user-dependent logic, such as creating courses and enrolling.

\section{CRUD implementation}

This section presents the relevant aspects of the \acrshort{crud} implementation,\footnote{\javaname{impl-crud/src/main/java/karsch.lukas}} mainly focusing on relational modeling using \hyperref[sec:jpa]{\acrshort{jpa}} and the audit log implementation.

\subsection{Architectural Overview}

The \acrshort{crud} application is built upon a traditional Layered Architecture (described in \autoref{sec:layered} and \autoref{sec:crud}), using on Controller, Service, and Repository layers. This classic separation of concerns ensures that responsibilities are clearly defined: Controllers handle incoming requests and responses, Services encapsulate the core business logic, and Repositories manage data persistence operations. This layered approach allows for independent development and testing of each layer.

While adhering to this layered structure, \emph{feature slicing} was additionally applied to enhance modularity. The application's components are grouped into logical, domain-specific modules such as \texttt{lectures}, \texttt{users}, \texttt{courses}, and \texttt{stats}. This slicing enables all relevant code for a particular feature to reside within its dedicated package. This approach aims to reduce coupling between functional areas of the application and makes it easier to locate and modify code related to a specific feature.

\subsection{Data Modeling}
\label{sec:crud-data-modeling}

All data in the CRUD implementation is present in the form of database / \gls{jpa} entities. Other objects like services and controllers are \emph{stateless}. The application uses a \hyperref[sec:crud]{normalized database} in the Third Normal Form.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{images/diagrams_crud/CRUD_ER_Diagram.drawio.png}
    \caption{Entity Relationship Diagram for the CRUD App}
    \label{fig:crud-er-diagram}
\end{figure}

Figure \ref{fig:crud-er-diagram} shows the \gls{er} Diagram for the CRUD app. It includes nine entities and a value object for the app's relational database schema. It should be noted that the auditing tables created by Hibernate Envers are not present in the diagram. \keyw{LectureEntity} stands out as the core entity in the system, having direct relationships to most other entities.

All entities and value objects are implemented using SpringBoot's \acrshort{jpa} integration. For example, an entity with a "One to Many" relationship can be implemented as presented in \autoref{lst:simple-one-to-many}.

\begin{lstlisting}[caption={Simple JPA entity with a "One to Many" relationship},captionpos=b,label={lst:simple-one-to-many}]
%%@Entity%% 
class LectureEntity {
    %%@Id%% 
    private UUID id; 

    %%@OneToMany(fetch=FetchType.LAZY)%%
    private List<EnrollmentEntity> enrollments; 
}
\end{lstlisting}

The \javaname{@Entity} annotation informs \acrshort{jpa} that the class should be mapped to a database table. If the schema generation feature is enabled, \acrshort{jpa} automatically creates a table structure that mirrors the class definition. In production environments where this feature is typically disabled, developers must provide SQL scripts to manually define the expected structure. This is commonly achieved either by including a basic initialization script or by utilizing dedicated database migration tools such as Flyway\footnote{\url{https://github.com/flyway/flyway}} or Liquibase\footnote{\url{https://www.liquibase.com/}} to manage versioned schema changes.

Each entity must include a field annotated with \javaname{@Id}, which serves as the unique primary key for the corresponding database record.

The \keyw{@OneToMany} annotation defines a relational link between two entities. While the collection is accessed in Java as a standard list via \keyw{lecture.getEnrollments()}, \acrshort{jpa} manages this behind the scenes using a foreign key relationship. The \texttt{fetch} parameter determines when this data is retrieved: \texttt{LAZY} loading defers the database query until the collection is explicitly accessed in the code, whereas \texttt{EAGER} loading fetches the related entities immediately alongside the parent object.

\subsection{Request Handling}

The request handling process in the CRUD application follows the flow described in \autoref{sec:layered}. A request reaches one of the web controllers (classes annotated with \keyw{@Controller}). The controller delegates the request to a service object. The service applies business logic to create, update or retrieve entities from the database using one or several repositories. Finally, the service returns a \gls{dto}, which the controller wraps in a \gls{http} response that is sent back to the client.

\subsection{Encapsulation and API Boundaries}
\label{sec:crud-encapsulation-and-api-boundaries}

The design of the \acrshort{crud} prototype aims to create a clear separation between the internal logic and the external API. This is primarily achieved through the shared \texttt{api} module, described in \autoref{sec:shared-base-module}, which defines the \glspl{dto} that form the public contract for all communication. The intention is that internal data structures like database entities are always converted to these \glspl{dto} before being exposed, encapsulating the implementation details. This creates a boundary between clients and service internals.

However, achieving perfect encapsulation in a Layered Architecture proves challenging. While feature slicing was applied and \glspl{dto} provide a boundary at the controller level, the underlying entity classes are often referenced across different packages, especially when they have relationships with each other (for example, the \keyw{LectureEntity} and \keyw{CourseEntity}). Furthermore, services and repositories are frequently injected and called throughout the application, leading to a tightly coupled system where the boundaries between modules can become blurred. This may make it difficult to modify one part of the system without impacting others.

\subsection{Auditing and Temporal Queries}
\label{sec:crud-auditing}

There are several strategies to implement an audit log, each with its own trade-offs:

\begin{enumerate}
    \item \textbf{Manual Logging}: Developers explicitly call a logging service in every service method that modifies data. While simple, this can lead to code duplication and is prone to human error, such as developers forgetting to add a log statement. A simple code example is presented in \autoref{lst:audit-log-code-example}.

          \begin{lstlisting}[caption={Code example for manual audit logging. Adapted from~\cite{fowler_audit_2004}},captionpos=b,label={lst:audit-log-code-example}]
public void updatePhoneNumber(User user, int newNumber) {
    logChange(Date.now(), user, user.getPhoneNumber(), newNumber, "UserRequestedNumberChange");
    user.setPhoneNumber(newNumber);
}

void logChange(
    Date date, User user, Object oldValue, Object newValue, String context
) {
    LogEntry logEntry = new LogEntry(date, user, oldValue, newValue);
    logRepository.persist(logEntry);
}
\end{lstlisting}
    \item \textbf{Database Triggers or Stored Procedures} can capture changes automatically and directly on the database. This guarantees that no change is missed, even if made outside the application. \textcite[515]{ingram_design_2009} mentions that database triggers run on a "per-record" basis, meaning the logic is run for each changed record individually. This may lead to degraded performance during batch operations, which is why stored procedures should be preferred over triggers for auditing concerns. It is also worth noting that this approach ties the auditing logic to a specific database, making it less portable.
    \item \textbf{JPA Entity Listeners}: JPA's lifecycle events (\texttt{@PrePersist}, \texttt{@PreUpdate}, etc.) can be used to intercept changes. Inside event handling functions designed for those events, it is possible to capture the changes and persist them in separate auditing tables. This approach is database-independent and keeps the logic within the Java application, allowing access to application internals like beans and Spring's security context. In full-grade applications built using Spring Security, the security context lets developers access the current user, making it possible to attach them to the new audit log entry. Additional context can also be added through thread-local or request-scoped variables~\cite[Section 13.2]{bauer_java_2016}. \label{item:jpa-entity-listener}
    \item \textbf{Hibernate Envers} is an auditing solution for JPA-based applications which automatically versions entities using the concept of revisions. Envers creates an auditing table for each entity. These tables store historical data whenever a transaction is committed. Custom revision entities and change listeners can be implemented to capture additional context~\cite{hibernate_envers_nodate}.
    \item \textbf{Change Data Capture (CDC)} is the process of extracting all changes to a data store into a form that can be replicated to other systems. For example, a stream of changes can continuously be applied to a search index~\cite[Chapter 11]{kleppmann_designing_2017}.
\end{enumerate}

The audit log in the \acrshort{crud} prototype is implemented using Hibernate Envers. This solution was chosen because it seamlessly integrates with existing JPA entities to manage historical versions of data in dedicated audit tables.

\subsubsection*{Enabling Auditing on Entities}

To track changes for a specific entity, it must be annotated with \keyw{@Audited}. In this implementation, a common base class \texttt{AuditableEntity}\footnote{\javaname{impl-crud/src/main/java/karsch.lukas.audit.}\keyw{AuditableEntity}} is used to handle basic auditing metadata such as creation and modification timestamps using Spring Data JPA annotations. \autoref{lst:audited-entity} presents the state of an entity after enabling Envers auditing. Apart from the \keyw{@Audited} annotation, no changes are necessary, unless developers wish to exclude certain fields from auditing, in which case \keyw{@NotAudited} can be used.

\begin{lstlisting}
%%@Entity%%
%%@Audited%%
public class CourseEntity extends AuditableEntity { 
    @Id @GeneratedUuidV7
    private UUID id;
    // all fields remain unchanged 
} 
\end{lstlisting}
{
\captionof{lstlisting}[Auditing configuration for CourseEntity]{Auditing configuration for \keyw{CourseEntity} (\javaname{impl-crud/src/main/java/karsch.lukas.courses.}\keyw{CourseEntity}})
    \label{lst:audited-entity}
}

\subsubsection*{Custom Revision Entity and Listener}

While Envers provides a default revision table (storing only a revision ID and timestamp), a custom implementation is required to capture application-specific context, such as the user responsible for the change and a descriptive, optional context which allows capturing additional information about a change.

As shown in \autoref{lst:custom-revision-entity}, the \keyw{CustomRevisionEntity} extends Envers' \keyw{DefaultRevisionEntity} to include the fields \keyw{revisionMadeBy} and \keyw{additionalContext}.

\begin{lstlisting}
%%@Entity%%
%%@RevisionEntity%%(UserRevisionListener.class)
public class CustomRevisionEntity extends DefaultRevisionEntity {
    private String revisionMadeBy; 
    private String additionalContext;
}
\end{lstlisting}
{
\captionof{lstlisting}[Custom revision entity]{Custom Envers revision entity (\javaname{impl-crud/src/main/java/karsch.lukas.audit.}\keyw{CustomRevisionEntity})}
\label{lst:custom-revision-entity}
}

The association between a transaction and this metadata is handled by the \keyw{UserRevisionListener}. This listener intercepts the creation of a new revision and populates the fields by accessing the current request scope and a custom \keyw{AuditContext} bean. Its implementation is detailed in \autoref{sec:capturing-request-scoped-context}.

\subsubsection*{Capturing Request-Scoped Context}
\label{sec:capturing-request-scoped-context}

To ensure the audit log contains meaningful information about why or by whom a change was made, the implementation utilizes Spring's \keyw{@RequestScope}. This annotation can be placed on beans, which will then be request-scoped, meaning they are re-created for each request. This annotation is used on two beans: \keyw{RequestContext}, holding information about the current user, and \keyw{AuditContext}, which is a bean able to capture additional context for auditing purposes. As \keyw{UserRevisionListener} is a Hibernate specific class living outside of Spring's managed environment, a static \keyw{getBean} method is used to access the relevant Spring beans.

\begin{lstlisting}
public class UserRevisionListener implements RevisionListener {
    %%@Override%%
    public void newRevision(Object revisionEntity) {
        CustomRevisionEntity rev = (CustomRevisionEntity) revisionEntity;

        if (isInsideRequestScope()) {
            RequestContext ctx = SpringContext.getBean(RequestContext.class);
            AuditContext audit = SpringContext.getBean(AuditContext.class);
            
            rev.setRevisionMadeBy(ctx.getUserType() + "_" + ctx.getUserId());
            rev.setAdditionalContext(audit.getAdditionalContext());
        } else {
            rev.setRevisionMadeBy("SYSTEM");
        }
    }
}
\end{lstlisting}
{
\captionof{lstlisting}[Implementation of the Revision Listener]{Implementation of the Revision Listener (\javaname{impl-crud/src/main/java/karsch.lukas.audit.}\keyw{UserRevisionListener})}
\label{lst:revision-listener}
}

\subsubsection*{Global Auditing Configuration}

Finally, the \texttt{AuditingConfig}\footnote{\javaname{impl-crud/src/main/java/karsch.lukas.audit.}\keyw{AuditingConfig}} configuration class connects the application's custom time provider to the JPA auditing infrastructure. This ensures that both the standard \texttt{createdAt} fields and the Envers revision timestamps are synchronized with the application's internal clock, which is essential for consistent testing. Additionally, the configuration connects the application's request context to the auditing infrastructure, providing information about the current user. In a full-grade application, Spring security would provide the user context, though for this project, a simpler solution was preferred, as described in \autoref{sec:authentication-authorization}.

\subsubsection{Reconstructing Historic State}

Envers stores its revision data and historical records in special auditing tables. These tables should contain all necessary information to reconstruct historic state. Envers provides a specific \gls{api} which can be queried to reconstruct historical state. This \gls{api} was used to implement the "reconstruction" use-case in the application which allows users to query their grade history for a specific assessment. The implementation of this service method is outlined in \autoref{lst:envers-historical-query}.

First, \acrshort{jpa}'s entity manager is used to obtain an instance of the AuditReader class, which provides methods to create historic queries. Using the \keyw{reader.createQuery()} method, it is possible to create a query instance by matching a specific class for which revisions shall be fetched, as well as adding a filter to match the relevant entity using its ID. Beyond filtering revisions by ID, Envers enables developers to add additional matchers based on revision properties. Here, the revision property \keyw{timestamp} is used to define the relevant date bounds.

Once the query is built, the result list can be fetched. The result is a list containing arrays of objects. More precisely, each list entry is a \emph{\gls{tuple}}. The first value is the historic entity, and the second value is the revision entity created for this specific revision. Because a custom revision entity is registered, the type of this revision entity is \keyw{CustomRevisionEntity}.

\begin{lstlisting}
public GradeHistoryResponse getGradeHistory(
    UUID studentId, UUID assessmentId) {
    var assessment = fetchAssessment(assessmentId);
    var grade = fetchGrade(assessmentId, studentId);

    AuditReader reader = AuditReaderFactory.get(entityManager);

    AuditQuery query = reader.createQuery()
            .forRevisionsOfEntity(AssessmentGradeEntity.class, false, true)
            .add(AuditEntity.id().eq(grade.getId())); // match by entity ID

    if (startDate != null) {
        query.add(AuditEntity.revisionProperty("timestamp").gt(
                startDate.toEpochMilli())
        );
    }
    if (endDate != null) {
        query.add(AuditEntity.revisionProperty("timestamp").le(
                endDate.toEpochMilli())
        );
    }

    List<Object[]> results = query.getResultList();

    var gradeChanges = results.stream()
            .map(result -> {
                AssessmentGradeEntity entity = (AssessmentGradeEntity) result[0];
                CustomRevisionEntity revision = (CustomRevisionEntity) result[1];

                return new GradeChangeDTO(
                        lectureAssessmentId,
                        entity.getGrade(),
                        revision.getTimestamp()
                );
            })
            .toList();
    
    return new GradeHistoryResponse(gradeChanges);
}
\end{lstlisting}
{
\captionof{lstlisting}[Reconstructing historic state using Envers]{Reconstructing historic state using Envers, simplified code example adapted from \keyw{impl-crud/src/main/java/karsch.lukas.stats.StatsService}}
\label{lst:envers-historical-query}
}

\subsection{Tracing Request Flow}

\autoref{fig:crud-diagram} presents the flow of two requests through the \acrshort{crud} implementation. The first request is a \texttt{POST} request, meaning it writes something. The client sends their request to the web controller, which calls a service using the request body and, optionally, additional information about the requesting user. The service uses its own or external service methods to validate the request. If validation passes, the service creates a \gls{jpa} entity and persists it to its \gls{jpa} repository. Afterward, the service returns the \texttt{UUID} of the created entity to the controller, which finally responds to the client by wrapping the service result in an \gls{http} response.

As reads pass through the same components as writes, a subsequent read request is also present in the diagram. The client sends a \texttt{GET} request, which is received by the controller that then calls a service method to fetch the requested data. The service may apply additional logic, e.g. filters. Then, it selects the data from the repository, maps the result to a \gls{dto} and returns it to the controller. The controller sends an \gls{http} response with status code 200, containing the response body.

\begin{figure}[H]
    \includegraphics[width=\textwidth, inner]{images/diagrams_crud/mermaid-diagram-2026-02-09-141443.png}
    \caption{Reads and writes in CRUD / Layered Architecture. Data Store omitted}
    \label{fig:crud-diagram}
\end{figure}

\section{ES-CQRS implementation TODO: refine language}
\label{sec:es-cqrs-implementation}

\subsection{Architectural Overview}
\label{sec:architecture-overview}

The architecture of the \texttt{impl-es-cqrs} application\footnote{\javaname{impl-es-cqrs/src/main/java/karsch.lukas}} differs from the traditional Layered Architecture seen in the \texttt{impl-crud} application. While the CRUD implementation also has some vertical slicing, the ES-CQRS implementation is much more explicit about it. The code is organized into "features", each representing a vertical slice of the application's functionality (e.g., \texttt{course}, \texttt{enrollment}, \texttt{lectures}). Each feature is self-contained and includes its own command handlers, event sourcing handlers, query handlers, and its own web controller, if needed.

An architecture like this is descriptive and able to communicate the features of a project at a glance. As clean architecture is not in the scope of this thesis, the separation into features with clear naming conventions for Command and Query components is sufficient. It should be mentioned that in many "vertical slice" architectures, the separation goes even further than described here, creating separate packages for each use-case, such as \keyw{GetLecture}, \keyw{CreateCourse}, and so on.

\subsection{Data Modeling}
\label{sec:cqrs-data-modeling}

In the CRUD application, \emph{Data Modeling} simply referred to relational modeling, because all data is present in the form of database tables which are written to and read from by all the components. In the ES-CQRS application, data is separated into writes and reads. The "data model" in ES-CQRS consists not just of tables and rows, but of event types, such as \keyw{CourseCreatedEvent}, and an event stream.

Data flow between components is decoupled through the use of Events, Commands and Queries. These message types facilitate all communication in the application.

The ES-CQRS application's Aggregates, which are central to Command handling in CQRS, are \keyw{CourseAggregate}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.course.commands.CourseAggregate}}, \keyw{LectureAggregate}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.lectures.commands.LectureAggregate}}, \keyw{EnrollmentAggregate}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.enrollment.commands.EnrollmentAggregate}}, \keyw{StudentAggregate}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.student.commands.StudentAggregate}} and \keyw{ProfessorAggregate}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.professor.commands.ProfessorAggregate}}. Unlike CRUD's \gls{er} model where \keyw{LectureEntity} has a foreign key to a professor, the \keyw{LectureAggregate} stores only a \keyw{professorId}. This ensures that each aggregate can be loaded and versioned independently in the Event Store.

Sagas act as process managers, but they are also data. For each process requiring a Saga, a new instance of that Saga is created. Sagas are long-running and serializable, storing all data that is relevant to their business logic.

Events, which carry facts about what happened in the system, are emitted by the command side and can be received and processed by the read-side, which then builds its projections. Projections can be seen as "derived data" which is built from events. Each Query use-case can and should create its own projections which contain exactly the data that is relevant to answer the respective Query.

Projections maintain specialized, denormalized datasets that are optimized for read performance. To eliminate the need for JOINs during querying, relationships are persisted inside JSON columns rather than relational foreign keys. This alignment ensures that projection schemas mirror the structure of the \glspl{dto} they serve, allowing the Query handler to return data with minimal transformation and using just one simple SELECT statement.

An example of a projector that stores data in such a way is the \keyw{LectureProjector}\footnote{\javaname{impl-es-cqrs/src/main/java/}\keyw{karsch.lukas.features.lectures.queries.LectureProjector}}. It demonstrates the fact that each projector maintains its own view of the system. Projectors must not use Axon's \keyw{QueryGateway} to get access to any data needed for the projection. One reason for that is the fact that when \emph{rebuilding} projections, a common use case in event sourcing, the projectors should be able to run in parallel. If projectors depend on each other, this can result in one projection attempting to query data from another projection that is not yet up to date. This is why the \keyw{LectureProjector} not only maintains a view of lectures, but also of courses, professors and students, which are then used when building the lecture's projection.

\subsection{Request Handling}
\label{sec:es-cqrs-request-handling}

This section describes how different components of the ES-CQRS application handle requests. Diagrams illustrating the flow of both commands and queries are available in \autoref{sec:es-cqrs-tracing-request-flow}.

\subsubsection{Command Side}
\label{sec:command-side}

Write requests (Commands) are received by a SpringBoot controller. The controller transforms the request into a Command message which is dispatched to the Command side using the \keyw{CommandGateway}. The Command side is responsible for handling all state changes in the application. It is implemented using the Aggregates and Sagas described in \autoref{sec:cqrs-data-modeling}.

Most command handling occurs inside the Aggregates, however the enrollment of students is a use-case spanning across two Aggregates. This required the external Command handler \keyw{EnrollmentCommandHandler} to be implemented.

\keyw{AwardCreditsSaga} is a Saga which was manages the process of awarding credits to students. The Saga is initiated when an \keyw{EnrollmentCreatedEvent} occurs. It then waits for a \keyw{LectureLifecycleAdvancedEvent} with the status \texttt{FINISHED}. Once this event is received, the saga sends an \keyw{AwardCreditsCommand} to the \keyw{EnrollmentAggregate}. The saga ends when it receives a \keyw{CreditsAwardedEvent}. This ensures that credits are only awarded after a lecture is finished, and all assessments have been graded.

Unlike the CRUD application, which calculates awarded credits based on the current state of a lecture, the ES-CQRS implementation makes the fact that credits are awarded explicit through an event. Even when changing the logic of the Saga later on, credits which have already been awarded will not be revoked, unless additional, explicit logic is implemented (e.g. by applying a \keyw{CreditsRevokedEvent}).

\subsubsection{Read Side}
\label{sec:read-side}

Read requests (Queries) are also received by a SpringBoot controller, which creates a Query object and dispatches it to the \keyw{QueryGateway}. The queries are routed to query handlers which can efficiently fetch data from their dedicated projections, as described in \autoref{sec:cqrs-data-modeling}. It is important to keep in mind that projections are built asynchronously, meaning they are eventually consistent and may not always reflect the latest changes applied by the command side.

\subsection{Encapsulation and API Boundaries}
\label{sec:cqrs-encapsulation-and-api-boundaries}

Like the \acrshort{crud} application, this prototype also implements Controller interfaces defined by the shared \texttt{api} module. However, each feature slice contains its own \texttt{api} package that is shared between web controllers, command side and read side. This "internal" \gls{api} maps the application's public interface to \gls{cqrs} semantics by defining specific Command and Query classes which target Command and Query Handlers. These feature-specific \texttt{api} packages are the only public packages in a feature slice, meaning communication across package boundaries is only possible using the defined Commands and Queries.

The public \gls{api} of the application is exposed through its Controllers, which only interact with the \keyw{CommandGateway} and \keyw{QueryGateway}. This ensures that all interactions with the system internals go through the proper channels and that underlying implementations can be changed without affecting the clients.

\subsection{Auditing and Temporal Queries}

As described in \autoref{sec:event-sourcing}, no additional audit log has to be implemented when using \acrlong{es}. The application's state can be reconstructed using the Event Stream by rehydrating Aggregates (Command-side) and by replaying projections (Read-side), if desired.

Temporal queries are implemented differently than in the \acrshort{crud} prototype. Using Envers, it is possible to select a specific range of revisions based on indexed columns, for example a "date" column. When using \acrlong{es}, all events have to be replayed from the Event Stream. Axon offers a method to read all events emitted by one Aggregate. The Event Stream returned from this function then has to be filtered to match the relevant events. These events can be applied to temporary projections or collected into a list. \autoref{lst:temporal-query-cqrs} presents how this workflow is used to query the grade history for a student.

\begin{lstlisting}
%%@QueryHandler%%
public GradeHistoryResponse getGradeHistory(
    GetGradeHistoryQuery query
) {
    final UUID enrollmentId = getEnrollmentIdFromQuery(query);

    final List<GradeChangeDTO> gradeChanges = eventStore
            .readEvents(enrollmentId.toString())
            .filter(msg -> eventTypeMatches(msg, query))
            .filter(msg -> eventIdMatches(msg, query))
            .filter(msg -> matchesDateFilter(msg, query))
            .asStream() // turn into Java Stream 
            .map(msg -> {
                LocalDateTime changedAt = getEventTimestamp(msg);
                GradeAssignedEvent payload = msg.getPayload();
                return new GradeChangeDTO(payload.assessmentId(), payload.grade(), changedAt);
            })
            .toList();

    return new GradeHistoryResponse(
            query.studentId(),
            query.lectureAssessmentId(),
            gradeChanges
    );
}
\end{lstlisting}
{
\captionof{lstlisting}[Temporal Query in ES-CQRS implementation]{Simplified code for a Temporal Query in the ES-CQRS implementation. Adapted from {\javaname{impl-es-cqrs/src/main/java/karsch.lukas.features.stats.queries.gradeHistory.GradeHistoryProjector}}}
\label{lst:temporal-query-cqrs}
}

\subsection{Tracing Request Flow}
\label{sec:es-cqrs-tracing-request-flow}

This section illustrates the flow of commands and queries through the system. Axon's \keyw{CommandGateway} and \keyw{QueryGateway} are used in controllers to decouple them from the internals of the application. The gateways create location transparency: a controller does not need to know where its commands and queries are being routed to --- the message may be handled inside the same JVM or on a different machine~\cite{axoniq_messaging_2025}.

Because reads and writes take different paths through the application, two separate diagrams are presented.

\subsubsection{Command Request Flow}
\label{sec:command-request-createcoursecommand}

\autoref{fig:es-cqrs-command-flow} illustrates the flow of a command through the system. Upon receiving a request, the controller constructs a specific \keyw{Command} object containing the request data and dispatches it through the \keyw{CommandGateway}. This gateway is responsible for routing the command to the appropriate destination, typically an \keyw{Aggregate} constructor or another method annotated with \keyw{@CommandHandler}. The command handler verifies that the command is allowed to be executed by performing validation logic and business rule checks. If the validation is successful, the aggregate triggers a state change by applying a corresponding \keyw{Event} via the \keyw{AggregateLifecycle.apply()} method. This action notifies the system of the change and persists the event by recording it in the event store.

After being applied, Axon routes the event to all subscribed handlers. The aggregate's \keyw{@EventSourcingHandler} is executed, updating the aggregate's internal state. It is worth noting that only the fields necessary for identifying the aggregate or maintaining its consistency are typically stored in the aggregate state, while other properties may be ignored on the command side. Any read-side projectors with \keyw{@EventHandlers} for the event are also executed, usually asynchronously, after the event is applied to update the projection databases.

\begin{figure}[H]
    \includegraphics[width=\textwidth, inner]{images/improved_diagrams_cqrs/mermaid-diagram-2026-02-09-141148.png}
    \caption{Sequence Diagram: Command Flow inside the ES-CQRS application}
    \label{fig:es-cqrs-command-flow}
\end{figure}

\subsubsection{Query Request Flow}
\label{sec:query-request-findallcoursesquery}

\autoref{fig:es-cqrs-query-flow} illustrates the flow of a query through the application. The request is received by a REST controller, which creates a \keyw{Query} instance and sends it to Axon's \keyw{QueryGateway}. The gateway routes the query to the appropriate \keyw{@QueryHandler} method responsible for that specific query type. The query handler accesses its respective projection repository to fetch the required data, maps the entities to \acrshortpl{dto}, and returns the result. The \keyw{QueryGateway} hands this result back to the controller, which returns the data to the client.

\begin{figure}[H]
    \includegraphics[width=\textwidth, inner]{images/improved_diagrams_cqrs/mermaid-diagram-2026-02-09-140344.png}
    \caption{Sequence Diagram: Query Flow inside the ES-CQRS application}
    \label{fig:es-cqrs-query-flow}
\end{figure}

\section{Infrastructure}
\label{sec:infrastructure}

The project's infrastructure is designed for consistency and reproducibility across development and testing environments. It is composed of a containerized environment for running the applications and their dependencies, an automated \gls{vm} provisioning setup for performance testing, as well as an integration testing strategy using \glspl{testcontainer}, described in \autoref{sec:contract-test-implementation}.

\subsection{Containerized Services}
\label{sec:containerized-services}

The core of the infrastructure is defined in a \gls{docker} compose file at the root of the project, which orchestrates the deployment of the two primary applications and their external dependencies: a \hyperref[sec:postgresql]{PostgreSQL} database, used by both applications, and an \hyperref[sec:axon]{Axon Server} instance, used by the ES-CQRS application.

A \keyw{postgres:18-alpine} container provides the relational database used by both applications. The database schema, user, and credentials are configured through environment variables. A volume is used to persist data across container restarts.

An \keyw{axoniq/axonserver} container provides the necessary infrastructure for the Event Sourcing and CQRS implementation, handling event storage and message routing. It is configured to run in development mode.

The CRUD and ES-CQRS applications are containerized using \keyw{Dockerfile}s. Both use \keyw{amazoncorretto:25} as the base image, and the compiled Java application (\keyw{.jar} file) is copied into the container and executed.

Configuration details, such as database connection strings and server hostnames, are externalized from the \keyw{application.properties} files. They are injected into the application containers at runtime as environment variables via the \keyw{docker-compose.yml} file, allowing for flexible configuration without modifying the application code.

\subsection{VM Provisioning for Performance Testing}
\label{sec:vm-provisioning}

To ensure a stable and isolated environment for performance benchmarks, a dedicated \acrshort{vm} setup is used. The process of creating and provisioning these \acrshortpl{vm} on a Proxmox host is fully automated.

A shell script, \keyw{create-vm.sh},\footnote{\javaname{performance-tests/vm/scripts/create-vm.sh}} orchestrates the creation of a \acrshort{vm} template from an Ubuntu 24.04 cloud image. Cloud images are pre-configured, lightweight variants of operating systems. This script works in conjunction with a CloudInit\footnote{\url{https://cloudinit.readthedocs.io/en/latest/}} configuration file that handles the provisioning of the \acrshort{vm} upon its first boot.\footnote{\javaname{performance-tests/vm/scripts/cloud-init.yml}}

During the provisioning process, a number of steps are executed. First, it is made sure that the system is up-to-date by installing any available software updates. Next, a `thesis` user is created for which the environment is configured. Afterward, the script installs all necessary software, including \gls{docker}, git, Conda, Python, k6, Maven, and Java 25. Once all necessary software is installed, the project's git repository is cloned and a Maven build is triggered. Finally, the \gls{docker} images are built. After these steps are completed, the provisioned \acrshort{vm} is ready to run the applications and load tests.

Instead of starting the \acrshort{vm} directly, the script shuts the \acrshort{vm} down and converts it into a Proxmox template, which can be re-created efficiently. This template is used to create the client and server \glspl{vm}.

The test environment and scenarios are defined as code to ensure reproducibility. Tests are executed in an isolated environment with fixed hardware allocations as specified in \autoref{table:hardware-specs}.

\begin{table}[htp!]
    \small
    \centering
    \begin{tabularx}{\linewidth}{lX}
        \toprule
        \textbf{Component} & \textbf{Specification}                                                      \\ \midrule
        CPU                & 13th Gen Intel(R) Core(TM) i7-13700H. 14 Cores, 20 total threads. Max. 5GHz \\
        RAM                & 32GB DDR4 (2x16GB), 3200 MT/s                                               \\
        Hard Drive         & SanDisk Plus SSD 1TB 2.5" SATA 6GB/s                                        \\
        \bottomrule
    \end{tabularx}
    \caption{Hardware specifications for the performance evaluation machine}
    \label{table:hardware-specs}
\end{table}

The physical host provisions two \glspl{vm}: the "client VM" for load generation and the "server VM" for the application and its dependencies (PostgreSQL and Axon Server). While hosting both on one physical machine makes network latency negligible, the "queueing delay" remains measurable at the client level, allowing for the identification of request queues building up on the server, indicating bottlenecks.

\section{Performance Evaluation through Load Tests}

This section describes the implementation of load tests.

\subsection{k6 Scripts}
\label{sec:k6-implementation}

The core of the load testing suite are the load-generating scripts developed using \hyperref[sec:k6]{k6}. \autoref{lst:create-course-k6-script} illustrates the implementation of a typical k6 script using the creation of courses with prerequisites as an example.\footnote{\javaname{performance-tests/k6/writes/create-course-prerequisites/create-course-prerequisites.js}}

After defining necessary imports, the test script extracts execution parameters from the \keyw{\_\_ENV} object which is injected by the k6 test runner. Most k6 scripts written for this project rely on \gls{rps}, representing the target iteration rate, and \texttt{TARGET\_HOST}, which is the URL the application under test is reachable at.

The value of \gls{rps} is used to define test options. Namely, a scenario, optional thresholds and the statistics to collect are defined. A test may have several scenarios, however in the k6 scripts used in this project, only one scenario per test is defined. Each scenario has a specific executor. In this case, the "ramping-arrival-rate" executor is used, as opposed to the "ramping-vus" executor. While the "ramping-vus" executor defines the number of virtual users interacting with the application (closed model), "ramping-arrival-rate" executors define the number of iterations per second (open model). This important distinction is described in more detail in \autoref{sec:load-test-theory}. Stages in a scenario define the "timeline" of \gls{rps}. In the given example, \gls{rps} are increased from 0 to the target \gls{rps} over a duration of 20 seconds. This \gls{rps} is then held for a duration of 80 seconds, before decreasing \acrshort{rps} back to 0 over a span of 20 seconds.

After defining test options, an optional setup function is implemented. It is executed once by k6, before running the load-generating "export default" function. In the setup function, seed data can be created. The given code example uses the setup function to create 10 prerequisite courses. Their IDs are returned from the setup function.

Data returned from the setup function can be passed to the "export default" function, which is the core of any load test. This is the function that is executed repeatedly to generate load. The implementation of this function in the given example is rather simple. One POST request is sent to the server. This request includes a payload which references a random number of prerequisite courses, as well as other required parameters for course creation.

\begin{lstlisting}[language=JavaScript]
// Imports omitted
const {TARGET_HOST, RPS} = __ENV;

export const options = {
    scenarios: {
        createCourses: {
            executor: "ramping-arrival-rate",
            timeUnit: "1s",
            preAllocatedVUs: RPS,
            stages: [
                {target: RPS, duration: "20s"},
                {target: RPS, duration: "80s"},
                {target: 0, duration: "20s"}
            ]
        }
    },
    thresholds: {
        'http_req_failed': ['rate<0.01'], // Error rate must be <1%
    },
    summaryTrendStats: ["med", "p(99)", "p(95)", "avg"],
};

export function setup() {
    const prerequisiteIds = createPrerequisites(10);
    return { prerequisiteIds };
}

export default function (data) {
    const {prerequisiteIds} = data; 

    const url = `${TARGET_HOST}/courses`;
    const prerequisiteCourseIds = selectRandomPrerequisiteIds();
    const payload = createPayload(prerequisiteCourseIds);
    const res = http.post(url, payload);
    checkResponseIs201(res);
}
\end{lstlisting}
{\captionof{lstlisting}[k6 script, simplified code example]{Simplified code example of a k6 script to test course creation. Adapted from \javaname{performance-tests/k6/writes/create-course-prerequisites/create-course-prerequisites.js}}}
\label{lst:create-course-k6-script}

\subsection{Load Test Lifecycle}

The k6 scripts alone are not enough to execute a large, repeated load test. While they can generate load on a running application and are capable of collecting client-side metrics, external lifecycle management is needed to control the infrastructure and ensure a clean environment in between each test run.

The lifecycle of repeated load tests is managed using python scripts. The core scripts are \keyw{perf\_runner.py}\footnote{\keyw{performance-tests/perf\_runner.py}} and \keyw{many\_runs.py}\footnote{\keyw{performance-tests/many\_runs.py}}. These scripts instrument the entire lifecycle of the application and k6 runs. They are responsible for starting the application using \gls{docker}, collecting server-side metrics using Prometheus and post-processing results.

The core logic within \keyw{perf\_runner.py} follows a defined flow for every single test run. It begins by determining the execution context. If a remote configuration is provided, it establishes a \gls{docker} Remote Context via \gls{ssh} to interact with the target \acrshort{vm}. It then deploys the application using \texttt{docker compose up}. Before directing any traffic towards the application, the Actuator's health endpoint is polled to ensure the application is running properly.

Once the application is healthy, the script sets up Prometheus for server-side monitoring. After dynamically generating a \javaname{prometheus.yml} configuration file, a Prometheus container is started, targeted to scrape the application under test. To ensure short-term spikes in latency or resource consumption can be captured, the configuration defines a polling interval of 2 seconds.

With the environment and monitoring active, the script invokes k6. Configuration parameters for the test run are expected to be defined in \javaname{metric.json}, which is a file placed alongside a test script. It includes metadata and parameters such as the number of \acrshortpl{VU} and the target host URL. These parameters are passed directly to the k6 engine via environment variables. Inside the k6 scripts, the \texttt{VU} environment variable defines the arrival rate for the \texttt{ramping-arrival-rate} executor. Unlike a fixed concurrency model, this approach ensures a consistent load by triggering a specific number of iterations per second. By decoupling the request rate from the response time of individual \gls{http} calls, the script maintains consistent pressure on the system even if latency fluctuates during the test.

After k6 completes its load generation, the script enters a data-extraction phase. It queries the Prometheus API to retrieve system-level metrics. Next, it parses the k6-summary.json file, which is a file generated by k6 that includes all metrics recorded during the run. The collected data is processed and merged into standardized CSV files (client\_metrics.csv and server\_metrics.csv).

Once all data is extracted, the system is ready for the next run. To prepare the environment, all containers need to be stopped first. That is done by running \javaname{docker compose down -v} inside the \gls{docker} remote context, with the \texttt{-v} argument explicitly removing all docker volumes. This ensures a clean state by purging the persistent data stores of PostgreSQL and Axon Server.

While \javaname{perf\_runner.py} manages the lifecycle of a single test, \javaname{many\_runs.py} acts as a high-level orchestrator, designed to automate large-scale comparative benchmarks by executing multiple iterations across both implementations by running a single command. The script can be configured to run an arbitrary number of tests, which will be executed for both applications. The script accepts the metric configuration files and passes them on to \javaname{perf\_runner.py}.

\subsection{Post Processing Test Results}

After extracting data from the k6 output and Prometheus, it is consolidated into a unified CSV format. This is necessary because the two systems use differing naming conventions and units: while k6 might report the 95th percentile latency as $p(95)$ in milliseconds, Prometheus might expose it through a complex PromQL query resulting in a label like $latency\_p95$, measured in seconds. Precisely, k6's $med$, $avg$ and percentile latency metrics are mapped to the Prometheus equivalent, laid out in \autoref{table:collected-metrics}. Performing this normalization step immediately after the test run means the collected data can easily be compared and visualized later.

\subsection{Testing "Freshness": Time to Consistency}

To assess the eventual consistency of the ES-CQRS architecture, a specialized test for the \hyperref[slo-freshness]{Freshness \acrshort{slo}} was developed.\footnote{\keyw{performance-tests/k6/time-to-consistency/create-lecture/create-lecture.js}} Unlike standard performance scripts, which measure the speed of isolated requests, this script is specifically designed to measure the synchronization delay between the command and query sides of the application. This delay, called eventual consistency, occurs because the write-side (Command) and read-side (Query) are strictly separated in \acrshort{cqrs}.

The primary difference from a typical k6 test lies in the execution flow within the default function. Rather than executing a single \gls{http} call, this test executes two calls to the application. First, it performs a POST request to create a lecture and captures the resulting ID. After creating the lecture, the script performs sleeps for exactly 0.1 seconds, the freshness threshold defined in the \ref{slo-freshness}. After this threshold, the application is expected to have synchronized the write- and read-side. Once the script wakes up again, it performs a GET request, attempting to fetch the newly created lecture.

To track the success rate of this request, the script introduces a custom \emph{Rate} metric named $read\_visible\_rate$. By manually adding true or false to this metric based on whether the lecture was found, indicated by a response status of 200, the script generates a percentage of "fresh" requests inside the required threshold of 100ms. This provides a clear statistical view of how reliably the ES-CQRS system maintains its "fresh" data under varying levels of load.

\subsection{A Function for Scalability}
\label{sec:my-scalability-function}

Following~\cite{jogalekar_evaluating_2000}, a function to determine the scalability of applications is established in this subsection. Their scalability metric, previously described in \autoref{sec:quantifying-scalability-metric}, serves as a basis for the scalability metric used in this study.

The cost function described in \autoref{eq:thesis-cost-function} is used.

\begin{equation}
    C(k) = w_1 * \text{CPU} + w_2 * \text{S} + w_3 \left( \frac{T}{200} \right) ^2 + w_4 \left( \frac{D}{10} \right)^2
    \label{eq:thesis-cost-function}
\end{equation}

This cost function is weighted, with $w_i$ being the weights for each metric. $S$ corresponds to storage size. More precisely, this value is calculated using a ratio of the two applications: the application with the larger storage consumption receives a cost penalty (e.g., 2.0 for twice the usage), while the smaller footprint is "rewarded", e.g. a value of 0.5 for half the usage. Furthermore, $T$ corresponds to $tomcat\_threads$, and $D$ corresponds to $hikari\_connections$. These metrics are normalized to their respective ceilings.

When testing time to consistency ("freshness"), the following term gets added to the cost function: $w_5(1 - R)^4$, with $R$ corresponding to $read\_visible\_rate$.

The concrete weights are as following: $w_1=1$, $w_2=0.5$, $w_3=1$, $w_4=1$, $w_5=3$. Storage consumption is weighed less, $read\_visible\_rate$ is weighed more.

Using the above cost function $C(k)$ and the following throughput function \autoref{eq:thesis-throughput} and the value function \autoref{eq:thesis-value-function}, a scalability metric can be calculated.

\begin{equation}
    \lambda(k) = RPS - dropped\_iterations\_rate
    \label{eq:thesis-throughput}
\end{equation}

\begin{equation}
    f(k) = \frac{1}{latency\_p95}
    \label{eq:thesis-value-function}
\end{equation}

The implementation of this scalability function is available in \javaname{scalability\_function.py}\footnote{\javaname{performance-tests/scalability\_function.py}}.

\subsection{All Implemented Load Tests}
\label{sec:all-load-tests}

Each \gls{l} is listed in table \autoref{tab:all-load-tests}.

\begin{table}[H]
    \small
    \centering
    \begin{tabularx}{\linewidth}{clXX}
        \toprule
        \textbf{Test}                & \textbf{Endpoint(s)}                            & \textbf{Name}                & \textbf{Seed Data}                                                                                                      \\
        \midrule
        \gls{l}1                     & POST /courses                                   & Create Courses Simple        & N/A                                                                                                                     \\
        \addlinespace
        \gls{l}2                     & POST /courses                                   & Create Courses Prerequisites & 10 courses                                                                                                              \\
        \addlinespace
        \gls{l}3                     & POST /lectures/\{lectureId\}/enroll             & Enrollment                   & Professor, one student per RPS, 100 courses and lectures                                                                \\
        \addlinespace
        \gls{l}4                     & GET /lectures                                   & Read lectures for student    & Professor, 50 courses and lectures, 100 students. Enroll each student in a lecture                                      \\
        \addlinespace
        \gls{l}5                     & GET /lectures/all                               & Read all lectures            & Same as L4                                                                                                              \\
        \addlinespace
        \gls{l}6                     & GET /stats/credits                              & Get credits                  & Professor, 50 students, 10 courses and lectures. Enroll each student in each lecture \& assign grade twice (one update) \\
        \addlinespace
        \gls{l}7                     & \makecell[tl]{POST /lectures/create,                                                                                                                                                                     \\
        GET /lectures/\{lectureId\}} & Time to consistency / Create lecture, then read & Professor, 50 courses                                                                                                                                  \\
        \addlinespace
        \gls{l}8                     & GET /stats/grades/history                       & Grade history                & Same as L6                                                                                                              \\
        \bottomrule
    \end{tabularx}
    \caption{All load tests}
    \label{tab:all-load-tests}
\end{table}

\section{Static Analysis}
\label{sec:static-analysis-impl}

The IntelliJ plugin \emph{MetricsReloaded}\footnote{\url{https://plugins.jetbrains.com/plugin/93-metricsreloaded}} was used to collect static analysis metrics from both applications.

The afferent ($C_a$) and efferent ($C_e$) coupling metrics, previously described in \autoref{sec:coupling-metrics}, can be calculated by MetricsReloaded on a per-package basis. Furthermore, the plugin can calculate metrics for incoming and outgoing dependencies on a class-basis. These can be mapped to the afferent and efferent coupling metrics, as shown in \autoref{table:dependency-metrics}. Additionally, MetricsReloaded calculates transitive (indirect) dependencies, allowing for a broader view of the system's dependencies, describing the number of packages a class depends on or the number of packages depending on a class.

\begin{table}[htp!]
    \centering
    \small
    \begin{tabularx}{\linewidth}{llX}
        \toprule
        \textbf{Plugin Metric} & \textbf{Theoretical Metric} & \textbf{Definition}                     \\
        \midrule
        $Dpt$                  & $C_a$ (per-class)           & Incoming dependencies                   \\
        \addlinespace
        $Dcy$                  & $C_e$ (per-class)           & Outgoing dependencies                   \\
        \addlinespace
        $Dpt^*$                & transitive $C_a$            & Indirect incoming dependencies          \\
        \addlinespace
        $Dcy^*$                & transitive  $C_e$           & Indirect outgoing dependencies          \\
        \addlinespace
        $PDcy$                 & N/A                         & Outgoing dependencies to other packages \\
        \addlinespace
        $PDpt$                 & N/A                         & Packages depending on this class        \\
        \bottomrule
    \end{tabularx}
    \caption{Class-based dependency metrics}
    \label{table:dependency-metrics}
\end{table}

Other metrics outlined in \autoref{sec:static-analysis-metrics} are also supported by MetricsReloaded, such as \gls{mood}, \gls{ck} and the stability metrics described in~\cite{martin_agile_2003}. It should be noted that the \gls{mood} metrics are only partly implemented, missing calculations for \gls{clf} and \gls{rf}, which is why no results will be presented for those metrics.
