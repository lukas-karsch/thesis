% !TeX root = ../main.tex
\chapter{Discussion}
\label{ch:discussion}

\section{Interpretation of Results}

TODO: explain this section. First, interpret results for each research question, finally give "recommendations" --- when is which architecture better suited?

\subsection{Performance and Scalability}
\label{sec:interpretation-performance}

The results obtained during load testing reveal a significant tradeoff between the two architectural patterns. The CRUD application excels in write throughput and resource efficiency, while the ES-CQRS application offers specialized advantages for complex read queries at the cost of higher overhead. In most write-heavy scenarios like \hyperref[sec:l1]{L1}, \hyperref[sec:l2]{L2}, and \hyperref[sec:l2]{L3}, the CRUD system maintains significantly lower latency and consumes fewer resources. In contrast, the ES-CQRS system frequently hits resource saturation --- reaching 200 threads and 10 database connections --- and violates latency thresholds as load increases. This divergence is especially visible in the enrollment test (L3), where the CRUD application manages much higher request volumes before performance degrades. Across nearly all tests, the ES-CQRS architecture requires more CPU and storage, often using double the disk space due to the overhead of storing both events and projections.

These differences are reflected in the calculated scalability metric $\psi$. While the CRUD application often exhibits values above 1.0, indicating efficient scaling where throughput increases outpace cost, the ES-CQRS application frequently shows values near zero under high load (e.g., $\psi \approx 0.01$ in L1). This metric serves as a useful tool for evaluating "productivity" by balancing throughput against resource costs like CPU and thread saturation. However, its usability is sensitive to how the "cost" function is weighted. For instance, the inclusion of a high penalty for projection lag (weighted at 3.0 in the model) heavily penalizes the ES-CQRS application's scalability score when consistency thresholds are missed.

However, the ES-CQRS application demonstrates its strength in specific read-heavy scenarios such as retrieving student credits (L6), where it provides a significant speedup compared to the CRUD application. While the CRUD application struggles with complex aggregations at high loads, reaching a scalability of $\psi \approx 0.00$ as its threadpool saturates, ES-CQRS benefits from pre-calculated read models that keep latencies low even at 3000 \gls{rps}. A similar advantage can be observed in L5 (reading a list of all lectures), because \gls{cqrs} is specifically designed to optimize these types of data retrievals. In these read-intensive contexts, the ES-CQRS application maintains a higher scalability factor (e.g., $\psi \approx 1.1$ at 2000 RPS) because the low latency and lack of complex DB joins compensate for its higher idle resource usage.

A critical drawback of \acrlong{es} and \gls{cqrs} is the projection lag observed in the freshness test (L7), where the application fails to reflect new writes on the read side within the required 100ms window (\ref{slo-freshness}) under heavy load. This eventual consistency means that even if reads have low latencies, they are not guaranteed to be up-to-date. Represented by the $read\_visible\_rate$ metric, this \emph{freshness} drops as low as $0.02$ for ES-CQRS at 400 \gls{ips}. This highlights a tradeoff for systems that require immediate data freshness: the mechanism that enables fast and scalable reads in ES-CQRS can also lead to stale data being served when the system is under pressure.

It should be noted that the results of L8 --- the historic reconstruction load test presented in \autoref{sec:l8} --- yielded a rather surprising result in terms of active database connections. Despite only using the database for two indexed ID lookups before streaming events from Axon's Event Store, the ES-CQRS application saturated the connection pool with a median of 10 active connections. This behavior is counter-intuitive compared to the CRUD implementation, which consistently maintains fewer active connections even though it performs more complex data fetching directly from the relational database through Envers.

TODO: higher Overhead in ES-CQRS in general.

TODO: Bottlenecks / headroom.

\subsection{Architectural Flexibility}
\label{sec:architectural-flexibility}

The static analysis results reveal distinct characteristics of the \gls{crud} and \gls{es}-\gls{cqrs} implementations. While metric suites like \gls{mood} and \acrlong{ck} provide a broad overview of code quality, the most insightful data for evaluating architectural flexibility results from the coupling and dependency metrics. These metrics provide a direct representation of how components interact and the extent to which a change in one area of the system propagates through others.

\subsubsection{Evaluation of Metric Utility}

The analysis indicates that transitive dependency metrics ($Dpt^*$ and $Dcy^*$), described in \autoref{sec:results-dependency}, are more useful than their direct counterparts ($Dpt$ and $Dcy$) for assessing the quality and coupling of an architecture. While the median values for direct dependencies are similar across both architectures, the \gls{es}-\gls{cqrs} approach shows a significantly narrower \gls{iqr} for transitive dependencies. In the \gls{crud} application, 50\% of classes have between 2 and 33 transitive dependents, whereas at least 75\% of \gls{es}-\gls{cqrs} classes have 7 or fewer. This suggests that the \gls{es}-\gls{cqrs} architecture more effectively isolates components, preventing a "rippling effect" of changes common in highly coupled architectures.

In contrast, the Distance from the Main Sequence ($D$), composed of Abstractness ($A$) and Instability ($I$), appears to be less accurate in this specific context. It is especially worth noting that a high Abstractness score does not inherently equate to a high level of \emph{functional abstraction}. For instance, the \gls{es}-\gls{cqrs} architecture utilizes many \gls{jpa} repositories on its Query side. These components are technically interfaces. This inflates the Abstractness score without necessarily having an architectural impact. Furthermore, these metrics are highly sensitive to the chosen package layout rather than the logic itself. A prime example is the \texttt{api} package in the \gls{es}-\gls{cqrs} application. It serves as a vital decoupling point between the Command and Query side, but because the classes are not abstract and highly depended upon, they appear "poor" according to traditional instability metrics despite their arguably high architectural value. Similarly, colocating Controller, Service and Repository classes in the same package in the CRUD application results in improved Instability values, even though the dependencies between classes are still present in the same way.

\subsubsection{Architectural Impact on Evolution and Scalability}

The structural differences between the two approaches have an impact regarding long-term flexibility and evolution. The \gls{crud} architecture displays higher \gls{cbo}, higher coupling ($C_a$, $C_e$) and more dependencies ($Dcy^*$, $Dpt^*$), and a larger "surface area" in the \gls{mood} metrics. This increased coupling implies that as the codebase grows, the complexity of making changes increases non-linearly, as each class is transitively linked to a larger portion of the system.

In contrast, the \gls{es}-\gls{cqrs} architecture demonstrates a structural advantage for scalability and evolution. The primary difference lies in the separation of concerns between writes and reads. By decoupling the Command and Query sides, the architecture maintains lower transitive coupling across the majority of the system.

Consequently, the \gls{es}-\gls{cqrs} approach likely provides a more seamless transition to horizontal scaling. Because the dependencies are already logically and physically partitioned (shown by the lower $Dcy^*$ and $PDcy$ values), the effort required to split the monolith into independent microservices is significantly reduced. This allows for specific parts of the system, such as high-traffic read models, to be scaled horizontally on separate infrastructure without requiring the entire application to be replicated. Additionally, Axon Framework provides location transparency, reducing the need to write additional boilerplate code when attempting to split the system into separate services. Therefore, while the \gls{es}-\gls{cqrs} architecture may have more outliers in package coupling, its fundamental structure provides the necessary isolation for the long-term scalability and independent evolution of system components.

\subsection{Traceability (TODO)}

TODO: schema evolution (maybe remove?), incorporate some "related work" findings.

The findings presented in this section are primarily derived from a synthesis of existing literature regarding system architecture and data integrity that was previously presented in \autoref{sec:basics-traceability-and-auditing} and \autoref{sec:traceability-related-work}. The performance data used to evaluate reconstruction efficiency was collected in L8 (\autoref{sec:l8}), but the qualitative comparison of reconstruction accuracy relies on the established literature.

The comparison between \gls{crud} and \gls{es}-\gls{cqrs} systems reveals a trade-off between the reliability of historical data and the speed of accessing it. In traditional \gls{crud} systems, the audit log acts as a secondary observer that records changes to a database. This architecture may suffer from the dual-write problem where the database update succeeds but the log entry fails. Consequently, the audit trail can diverge from reality, which may undermine the integrity required for strict legal compliance. Furthermore, \gls{crud} audit logs often capture the fact that data changed without preserving the specific business intent behind that change. Capturing and reconstructing intent requires additional measures in \gls{crud} systems, while in \gls{es}-\gls{cqrs}, events carry inherent metadata which contain intent.

Event-sourced systems address these accuracy concerns by treating the event stream as the sole source of truth. Because every state change is recorded as an immutable event, the system preserves the exact domain context and intent. This makes the reconstruction process deterministic and eliminates the risk of silent data divergence. Even if read-side projections do get out of sync, it is trivial to fix any bugs in their implementation and rebuild them afterward. However, the efficiency of historic reconstruction remains a challenge. While \gls{crud} systems can use indexed database tables and date filters to quickly retrieve specific historical snapshots, an \gls{es}-\gls{cqrs} system typically needs to replay the entire sequence of relevant events to reach a desired point in time.

Load testing results (L8) confirm that \gls{crud} architectures are significantly faster for simple history queries. Reconstructing a student's grade history, for example, proved more efficient in the \gls{crud} model, likely because it avoided the computational overhead of replaying event logs. While snapshots in \gls{es} can speed up the rehydration of Aggregates (current state), they are not applicable when replaying the full history for a time-travel query. Therefore, while \gls{es}-\gls{cqrs} provides superior accuracy and schema resilience for forensic auditing, the \gls{crud} approach remains more performant for frequent or high-volume historical lookups.

It should also be mentioned that frequent lookups of historic state are likely uncommon in typical applications. If a high volume of time-travel queries was a real use-case in an application, architects would most likely adopt an entirely different approach in storing current and historic state, such as time-series databases or creating specific database tables with validity ranges.

\subsection{Architectural Trade-offs and Recommendations (TODO)}

Abcdefg.

\section{Limitations of the Study}
\label{sec:limitations-of-the-study}

This research provides an empirical, quantifiable comparison between \gls{crud} and \gls{es}-\gls{cqrs} architectures. However, several technical and methodological limitations must be acknowledged when interpreting the results. One of these limitations is the infrastructure environment used for testing. Because both the load generation and the server-side components were hosted on \glspl{vm} running on the same physical machine, the observed network latency does not accurately reflect a distributed production environment. In a real-world scenario, services typically communicate across a physical network rather than on a single host. Particularly the ES-CQRS architecture involves a more complex chain of communication, including the command and query bus, aggregate handling, projections and event storage. In a distributed environment, the cumulative network "round trips" required for these steps would likely result in higher latencies than those recorded in this study's test setup.

Except for Axon Server's storage size, the server-side metrics were only collected from the SpringBoot application. Because the \gls{vm} also hosted PostgreSQL and Axon Server, the collected CPU metric ($process\_cpu\_usage$) does not capture the total system load. It is likely that the overall system CPU was fully saturated even when the server's CPU usage suggested remaining overhead. This is a threat to the validity of the performance data.

The accuracy of the benchmarking results was further affected by the testing configuration. In some load tests, a significant number of iterations was dropped at high RPS because the maximum number of \glspl{VU} in the k6 configuration was insufficient for the load. This means the results do not reflect the real performance under the respective load, as the actual load on the system was lower in these cases. Additionally, a more granular analysis would require measuring garbage collection pauses, memory allocation rates, and other system metrics. Furthermore, without profiling, the "root causes" of specific bottlenecks remain theoretical, as the collected data shows the \emph{results} of system stress rather than a detailed breakdown of internal execution delays. The performance analysis is also limited because the tests only varied the number of requests per second. Other factors, such as the size of the data being sent in POST requests or the volume of data fetched in queries, remained constant per test and were not evaluated.

The accuracy of server-side metrics collected through Actuator and Prometheus may be reduced under very high load because the metric collection in itself is bound to system resources and may start slowing down under high load. Also, the actuator endpoints themselves experience the same queueing delay as other requests.

Furthermore, although both applications were developed following industry standards and common best practices, it cannot be formally guaranteed that the implementations are entirely free of defects or suboptimal coding practices. Consequently, the observed performance metrics may be influenced by unidentified implementation errors rather than being representative of the underlying architecture.

Beyond the technical measurements, the given architectural evaluation is limited as it is simply a synthesis of static analysis. This study did not investigate the topic of schema evolution, which is the process of managing how data structures, such as events or database tables, change over time. In a long-running production system, the difficulty of evolving an event store's schema is an additional factor in the total cost of ownership and flexibility of an \gls{es}-\gls{cqrs} system. Similarly, managing complex database migrations in coupled \gls{crud} architectures without data-loss may introduce additional challenges.

Because the use case and the load patterns used in this study were artificially generated, they may not capture the unpredictable nature of real-world user behavior or specific business requirements.

While a load test was developed and executed for a simple history query (L8), the potential use-cases for time-travel queries are far wider. More complex historical queries involving several entities would have been a different challenge, and could have shown different results for the two architectures, both in implementation complexity and latencies.

Finally, the emphasis placed on certain architectural benefits, such as traceability or scalability, is inherently subjective. Different organizations or developers might prioritize \glspl{slo} or compliance requirements differently, which would alter the perceived value of one architecture over the other.

\section{Answering the Research Questions}

This section will provide a conclusive answer to the three sub-research questions, before providing a holistic answer to the main \glslink{rq}{research question}.

\subsection{RQ 1: Performance and Scalability (TODO)}
\label{sec:answering-rq-1}

\begin{quote}
    \textit{How do CRUD and ES-CQRS implementations perform under increasing load, and what are the resulting implications for system scalability and resource efficiency?}
\end{quote}

\subsection{RQ 2: Architectural Complexity and Flexibility (TODO)}
\label{sec:answering-rq-2}

\begin{quote}
    \textit{What are the fundamental structural differences between the two approaches, and how do these impact the long-term flexibility and evolution of the codebase?}
\end{quote}

\subsection{RQ 3: Historical Traceability (TODO)}
\label{sec:answering-rq-3}

\begin{quote}
    \textit{To what extent can CRUD and ES-CQRS systems accurately and efficiently reconstruct historical states to satisfy business intent and compliance requirements?}
\end{quote}

\subsection{Conclusion (TODO)}

Here, provide a final, holistic answer to the main research question.

\section{Further Work}
\label{sec:further-work}

\subsection{Improvements to the Method --- TODO remove this section?}

Fix limitations, basically

\begin{itemize}
    \item Run on the network
    \item Fix code: e.g. potential N+1 queries in CRUD, moving blocking lookups in ES-CQRS to external command handlers / interceptors
\end{itemize}

\subsection{Optimizations and Further Work}
\label{sec:optimizations-and-further-work}

This subsection outlines potential technical refinements for the existing implementations and identifies opportunities for future work. While the current results establish a baseline for both architectures, several optimization strategies could be applied to reduce the performance bottlenecks in both applications.

Beyond architectural changes, the underlying infrastructure and framework configurations offer room for improvement. While no tuning was done for this thesis on purpose to make "out-of-the-box" performance comparable, \autoref{tab:system-tuning} summarizes parameters that could be tuned to resolve the resource saturation and latency bottlenecks observed in the ES-CQRS and CRUD applications. Before doing any tuning, further profiling would be necessary to identify bottlenecks in function calls or queries.

\begin{table}[h!]
    \centering
    \small
    \begin{tabularx}{\linewidth}{lXX}
        \toprule
        \textbf{Keyword}          & \textbf{Action}                                                                                                                                               & \textbf{Goal}                                                                       \\ \midrule
        \textbf{Pool Tuning}      & Adjust Tomcat thread counts and HikariDB connection limits.                                                                                                   & Reduce queueing delays.                                                             \\ \addlinespace
        \textbf{Event Store}      & Tune Axon page sizes and set different snapshot thresholds.                                                                                                   & Reduce the number of expensive \gls{io} operations when reading long event streams. \\ \addlinespace
        \textbf{Reactivity}       & Implement Spring WebFlux\footnotemark[1] and reative JPA repositories\footnotemark[2].                                                                        & Free up worker threads while waiting for database or network responses.             \\ \addlinespace
        \textbf{Query Refinement} & Replace auto-generated Hibernate queries with custom JPQL queries, optimize further using \texttt{@BatchSize} and EAGER fetching options.                     & Eliminate inefficient queries and reduce the total number of database round-trips.  \\ \addlinespace
        \textbf{Serialization}    & Tune Jackson's serialization options. In ES-CQRS, JSON projections could be replaced by binary formats like Protobuf\footnotemark[3] or Kryo\footnotemark[4]. & Minimize CPU overhead, reduce projection storage size.                              \\ \addlinespace
        \textbf{Projections}      & Transition from JSON-based projections to flat, denormalized SQL-native tables.                                                                               & Eliminate serialization overhead and enable high-performance JDBC mapping.          \\
        \bottomrule
    \end{tabularx}
    \caption{Proposed System Tuning and Optimization Strategies}
    \label{tab:system-tuning}
\end{table}

\footnotetext[1]{\url{https://docs.spring.io/spring-framework/reference/web/webflux.html}}
\footnotetext[2]{\url{https://docs.spring.io/spring-data/jpa/reference/data-commons/api/java/org/springframework/data/repository/reactive/ReactiveCrudRepository.html}}
\footnotetext[3]{\url{https://protobuf.dev/}}
\footnotetext[4]{\url{https://github.com/EsotericSoftware/kryo}}

Additional performance gains could be achieved through the implementation of caching. Introducing a cache for frequently accessed student data could provide the CRUD application with read speeds comparable to \gls{cqrs} without the structural complexity of \acrlong{es}, though this introduces its own challenges regarding cache invalidation.

Furthermore, as this study evaluated both applications on a single machine, the assessment of scalability and architectural flexibility remains primarily theoretical. To provide empirical evidence for these scalability claims, it would be necessary to physically transition the systems into microservices and perform horizontal scaling. Only by implementing these structural changes can the practical performance limits and the true decoupling of the ES-CQRS pattern be fully validated. Additionally, the effort required to transform the monolithic structure into microservices would serve as a practical benchmark to validate the accuracy of the static analysis results.
