% !TeX root = ../main.tex
\chapter{Results}

\section{Performance}
\label{sec:performance-results}

This section describes results of load testing. Each \gls{l} is presented in order, describing the kind of endpoint and test that was employed.

For all load tests, the primary results are visualized through diagrams like latency-vs-load line plots. The raw numerical data, including confidence intervals and significance levels for all tested load levels, are provided in \autoref{appendix:results}.

\subsection{Significance}

The significance levels indicated in the tables inside the appendix are calculated using the \emph{Mann-Whitney U} significance test. This test is used because it doesn't require normally distributed samples and compares the \emph{rankings} of results rather than the averages, making it more resistant to outliers\cite[Chapter 13.3]{triola_elementary_2012}. In load testing, outliers (\glspl{tail-latency}) can create \emph{skewing} that would incorrectly bias a standard average-based test.

\subsection{Steady-state performance}

To capture the system's median CPU usage under load, the initial usage spike ("transient"), exhibited across all runs, was excluded. This approach mitigates the influence of startup spikes and resource initialization overhead, instead focusing on the steady-state performance. This process is called \emph{transient removal}~\cite{jain_art_1991}.

\subsection{Ratios}

When comparing the CRUD and ES-CQRS applications' performance, a "speedup" factor or ratio is calculated per metric and \gls{rps}. This ratio may be mentioned for textual descriptions of the resulting graphs, and is always present in the tables inside the appendix. The term "speedup" is used when comparing latencies, while the term "ratio" is used for other metrics. The given values are calculated like this: $\frac{metric_{crud}}{metric_{es\_cqrs}}$. Therefore, a $latency\_p95$ of 100ms for the CRUD application and a $latency\_p95$ of 50ms for the ES-CQRS application would result in a speedup of 2x for that specific metric at the respective \gls{rps}. Ratios involving the value zero for either application are marked as \emph{N/A}.

\subsection{Dropped Iterations}

In some tests, iterations were dropped, meaning that k6 skipped iterations and did not send requests to the server. This occurs if an iteration takes longer than 1 second and no more \glspl{VU}, which act as request processors, are available to k6. The fact that iterations were dropped during testing is mentioned when describing results, and the rate of dropped iterations per second ($dropped\_iterations\_rate$) is available in the results tables inside the appendix.

\subsection{Threadpool}

Each load test shows the threadpool usage ($tomcat\_threads$) of the application under test. The maximum value this metric can take in these tests is 200, as it SpringBoot's default configuration.

\subsection{Database Connections}

Each load test presents the number of used database connections of the application under test --- $hikari\_connections$. The maximum value this metric can take in these tests is 10, which can again be attributed to SpringBoot's default configuration.

It is important to clarify that a median value of zero active database connections does not imply a lack of database activity. Instead, this result is an artifact of the metric collection frequency and the statistical properties of the median. Resource consumption metrics were sampled at two-second intervals. In scenarios where database interactions completed within milliseconds, the majority of these snapshots captured the connection pool in an idle state. Consequently, while the database was used during request handling, a high rate of zero-value samples drives the median to zero.

\subsection{Data Store Size}

The size of the data store is calculated differently for both applications. The CRUD application uses PostgreSQL as its only data store. Therefore, $postgres\_size$ equals the application's data store size.

The total data store size for the ES-CQRS application is defined as the sum of the PostgreSQL projection size and the allocated Axon storage: $postgres\_size + axon\_storage\_size$. It is important to note that Axon Server allocates storage in fixed-size segments (or "pages") of 4MB. Because these segments are allocated eagerly, the total storage includes a minimum overhead of 8MB (one 4MB segment each for events and snapshots), regardless of the actual data density within those blocks. Consequently, the measured size represents the allocated capacity rather than the literal byte-count of the stored records.

\subsection{Graphs}

In graphs that show latencies, the shaded areas in the line graphs represent the \emph{confidence interval (CI)} of the latency measurements. The confidence interval is the range of values that is likely to contain the true answer. It estimates the level of uncertainty by providing a margin of error around a specific result.

Graphs showing resource consumption typically show the area between the 25th and 75th percentile in the shaded area, also called \emph{\gls{iqr}}. This shows the typical range of resource usage across runs.

The lines between the measured data points are interpolated, representing an estimation of performance trends across the full range of measurements. These lines help visualize the transition between different loads, though the actual values were only recorded at the marked intervals on the x-axis. In some cases, the x-axis omits intermediate labels for improved readability. However, all data points remain connected by interpolated lines to illustrate performance trends between measurements. For a complete view of every value, refer to the full results provided in \autoref{appendix:results}.

\subsection{Write Performance}

\subsubsection{L1: Create Courses Simple}
\label{sec:l1}

Professors can create courses using the \texttt{POST} \texttt{/courses} endpoint. The "simple" test case tests creation of courses \emph{without prerequisites}. This means that no validation is necessary to create a new entity, making this test the raw insertion performance.

\autoref{fig:l1_combined} presents line graphs comparing the endpoint's latency under increasing load using a logarithmic y-axis. The graphs describe the observed client-side and server-side latencies under varying loads of both applications by showing their $latency\_p50$ (median) and $latency\_p95$ (tail latency). \ref{slo-latency} defined the threshold for $latency\_p95$ at 100ms, meaning the ES-CQRS application failed to satisfy the \gls{slo} between 500 and 1000 \gls{rps}. Additionally, its $dropped\_iterations\_rate$ reaches a value of 51 at 1000 RPS. Meanwhile, the \gls{crud} application achieves a sub 10ms $latency\_p95$ until at least 1000 \gls{rps}.

It can be noted that the latency curve follows the same pattern in both the measurements made on the client and on the server, except for the ES-CQRS $latency\_p95$ which exhibits a value of over 1000ms on the client, but only around 300ms on the server.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/create_course_simple_latency-vs-load__client.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l1_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/create_course_simple_latency-vs-load__server.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l1_latency_vs_load_server}
    \end{subfigure}
    \caption[L1 Performance Metrics, load measured in \gls{rps}]{L1 Performance Metrics: Load measured in \gls{rps}. Detailed results in \ref{results:l1}.}
    \label{fig:l1_combined}
\end{figure}

\autoref{fig:l1_cpu_usage_vs_load} presents median CPU usage of the endpoint under increasing load. The ES-CQRS application generally has a higher CPU usage, exhibiting a value of $\approx$45\% at 1000 \gls{rps}, while the CRUD application uses $\approx$10\%. The CRUD application's CPU usage rises linearly, while the ES-CQRS application's CPU usage rises slower past 500 \gls{rps}.

The threadpool usage of both applications is visualized in \autoref{fig:l1_threadpool_usage}. At 500 \gls{rps}, ES-CQRS starts using more threads, finally reaching threadpool saturation --- meaning that all 200 possible threads of the threadpool are used --- at 1000 \gls{rps}. The CRUD application uses at most around 25 threads at 1000 \gls{rps}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/CPU_Usage_vs_Load.png}
        \caption{CPU Usage (\%) vs. Load}
        \label{fig:l1_cpu_usage_vs_load}
    \end{subfigure}
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/create-course-threadpool-usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l1_threadpool_usage}
    \end{subfigure}
    \caption[L1 Resource Usage, load measured in \gls{rps}]{L1 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l1}.}
    \label{fig:l1_resource_vs_load}
\end{figure}

In \autoref{fig:l1_data_store_vs_load}, the size of the data store under increasing load is presented. The CRUD application's data store, consisting only of the PostgreSQL database, exhibits a linear growth, reaching a size of $\approx$70MB at 1000 \gls{rps}. With 100,000 requests sent at 1000 \gls{rps}, this comes out to around 0.7kB per persisted course. The ES-CQRS graph also grows linearly. At 500 \gls{rps}, the size of the data store is about 60MB, a 1.5x higher storage consumption than the CRUD application. This equals around 1kB per persisted course. However, at 1000 \gls{rps}, the storage size decreases. This can be attributed to a projection lag caused by the eventual consistency present in the application and is explained further in \autoref{ch:discussion}. The true storage consumption of the ES-CQRS application can be assumed to be around 120MB, once all projections are updated.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/create-course-simple_db-connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l1_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-simple/data_store_size.png}
        \caption{Data Store Size vs. Load}
        \label{fig:l1_data_store_vs_load}
    \end{subfigure}
    \caption[L1 Database Usage, load measured in \gls{rps}]{L1 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l1}.}
    \label{fig:l1_database}
\end{figure}

These values correspond to the following scalability metrics for the CRUD application: $\psi(200, 500)\approx 5.4$, $\psi(500, 1000)\approx 1.4$; and the following scalability metrics for the ES-CQRS application: $\psi(200, 500)\approx 0.6$, $\psi(500, 1000)\approx 0.01$.

\subsubsection{L2: Create Courses Prerequisites}
\label{sec:l2}

This test also evaluates the performance of the endpoint described in \autoref{sec:l1}. However, before executing the load generation, a set of "prerequisite" courses are generated. Each iteration, a random number of these courses (0 to 5) are selected which are referenced during load generation. This creates the necessity to do additional checks on existing data, verifying whether the referenced courses actually exist.

The endpoint's performance, presented in \autoref{fig:l2_combined} using a logarithmic y-axis, is similar to the observations made in \hyperref[sec:l1]{L1}. After exceeding 500 \gls{rps}, the ES-CQRS application fails to satisfy \ref{slo-latency} with a $latency\_p95$ exceeding the threshold of 100ms. Additionally, its $dropped\_iterations\_rate$ reaches a value of 61. The CRUD application, on the other hand, is able to fulfill the latency threshold up to at least 1000 \gls{rps} without dropping iterations.

It can be noted that the latency curve follows the same pattern in both the measurements made on the client and on the server, except for the ES-CQRS $latency\_p95$ which exhibits a value of over 1000ms on the client, but only $\approx$360ms on the server at 1000 \gls{rps}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/course-prerequisites-latency-load-CLIENT.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l2_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/course-prerequisites-latency-load-SERVER.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l2_latency_vs_load_server}
    \end{subfigure}
    \caption[L2 Performance Metrics, load measured in \gls{rps}]{L2 Performance Metrics: Load measured in \gls{rps}. Detailed results in \ref{results:l2}.}
    \label{fig:l2_combined}
\end{figure}

\autoref{fig:l2_cpu_usage} presents the median $cpu\_usage$ of the endpoint under increasing load. The ES-CQRS application has a higher CPU usage, exhibiting a value of $\approx$45\% at 1000 \gls{rps}, while the CRUD application uses $\approx$10\%. The CRUD application's CPU usage rises linearly, while the ES-CQRS application's CPU usage rises slower past 500 \gls{rps}.

The threadpool usage of both applications is visualized in \autoref{fig:l2_threadpool_usage}. At 200 \gls{rps}, ES-CQRS starts using more threads, finally reaching threadpool saturation at 1000 \gls{rps}. The CRUD application uses at most around 25 threads at 1000 \gls{rps}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/courses-prerequisites-CPU-usage.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l2_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/courses-prerequisites-threadpool-usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l2_threadpool_usage}
    \end{subfigure}
    \caption[L2 Resource Usage, load measured in \gls{rps}]{L2 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l2}.}
    \label{fig:l2_resource_usage_cpu}
\end{figure}

\autoref{fig:l2_database} presents database usage statistics of both applications under increasing load.

The median used database connections are shown in \autoref{fig:l2_db_connections}. At 1000 \gls{rps}, the ES-CQRS application uses all available connections, while the CRUD application utilizes around 2.

In \autoref{fig:l2_data_size}, the size of the data store under increasing load is presented. The CRUD application's data store exhibits a linear growth, reaching a size of $\approx$107MB at 1000 \gls{rps}. With 100,000 requests sent at 1000 \gls{rps}, this comes out to roughly 1.1kB per persisted course --- around 60\% higher than when creating courses without prerequisites.

The ES-CQRS application's storage consumption initially follows a linear growth pattern. At 200 \gls{rps}, the data store occupies approximately 45MB, representing a 1.6x increase compared to the CRUD application—roughly 2.3kB per persisted course. However, as the load increases beyond 500 \gls{rps}, the observed storage growth decelerates, eventually showing a decline at 1000 \gls{rps}. Again, this can be attributed to projection lag. Once the system updates all projections, the true storage consumption of the ES-CQRS application is estimated to be approximately 225MB.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/courses-prerequisites-db_connections-usage.png}
        \caption{Database Connections vs. Load}
        \label{fig:l2_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/create-course-prerequisites/courses-prerequisites-data_size.png}
        \caption{Data Store Size vs. Load}
        \label{fig:l2_data_size}
    \end{subfigure}
    \caption[L2 Database Usage, load measured in \gls{rps}]{L2 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l2}.}
    \label{fig:l2_database}
\end{figure}

These values correspond to the following scalability metrics for the CRUD application: $\psi(200, 500)\approx 2.5$, $\psi(500, 1000)\approx 1.1$; and the following scalability metrics for the ES-CQRS application: $\psi(200, 500)\approx 0.4$, $\psi(500, 1000)\approx 0.02$.

\subsubsection{L3: Enrollment}

The endpoint \texttt{POST /lectures/\{lectureId\}/enroll} enrolls students to a lecture. Its performance under load up to 500 \gls{rps} is visualized in \autoref{fig:l3_combined} using a logarithmic y-axis.

The ES-CQRS application's $latency\_p95$ rises above 100ms between 50 and 100 \gls{rps}, violating \autoref{slo-latency}. The CRUD application's $latency\_p95$ and $latency\_p50$ remain below 10ms until 200 \gls{rps}, representing more than a 20x slowdown for the ES-CQRS application. Between 200 and 500 \gls{rps}, CRUD's P95 latency rises to over 1000ms, violating \ref{slo-latency}. At 500 \gls{rps}, ES-CQRS' $latency\_p95$ exceeds 10,000ms.

It is worth noting that starting from 200 \gls{rps}, the ES-CQRS's load tests started dropping iterations. $dropped\_iterations\_rate$ reached a value of around 240 at 500 \gls{rps}, at which point the CRUD application also exhibited dropped iterations with a rate of around 36.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment_latency-vs-load_client.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l3_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment_latency-vs-load_server.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l3_latency_vs_load_server}
    \end{subfigure}
    \caption[L3 Performance Metrics, load measured in \gls{rps}]{L3 Performance Metrics: Load measured in \gls{rps}. Detailed results in \ref{results:l3}.}
    \label{fig:l3_combined}
\end{figure}

\autoref{fig:l3_cpu_usage} compares CPU utilization by both applications as the load increases. The ES-CQRS application consistently requires more CPU than the CRUD application across all tested loads. At lower intensities (below 200 RPS), the ES-CQRS CPU usage grows, before peaking at around 42\% at 200 \gls{rps} and remaining at that level for 500 RPS. The CRUD application shows a steady increase in CPU consumption as load increases, reaching aroud 36\% at 500 RPS.

\autoref{fig:l3_threadpool_usage} illustrates the number of active threads utilized by each application to process the incoming load. At 25 and 50 RPS, both applications maintain an identical, stable baseline of 10 threads. Beyond 50 RPS, the utilized threads for ES-CQRS begin to increase. It reaches a maximum capacity of 200 threads at in between 100 and 200 \gls{rps} and remains saturated at that limit through 500 RPS. In contrast, the CRUD application maintains its baseline of 10 threads until 200 RPS. Even at the maximum load of 500 RPS, its median thread usage remains at around 17 threads. However, it should be noted that the \gls{iqr} at 500 RPS spans up to 200 threads, indicating a high variance in the measured results.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment-cpu-usage-vs-load.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l3_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment-threadpool_usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l3_threadpool_usage}
    \end{subfigure}
    \caption[L3 Resource Usage, load measured in \gls{rps}]{L3 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l3}.}
    \label{fig:l3_resource_usage_cpu}
\end{figure}

Database usage under increasing load is visualized in \autoref{fig:l3_database}. \autoref{fig:l3_db_connections} shows the median active database connections. It can be seen that the ES-CQRS application reaches its peak at around 4 connections simultaneously at 200 \gls{rps}, plateauing for the final measured load of 500 \gls{rps}. On the other hand, the CRUD application uses a median of 0 connections until 100 \gls{rps}. At this point, the graph starts rising, reaching a median of 4 at 500 \gls{rps} with a wide \gls{iqr} spanning from 2 to 10.

Size of the data store is presented in \autoref{fig:l3_data_size}. The CRUD application shows a linear growth, reaching a final size of 41MB. In contrast, ES-CQRS shows a sharper growth. At 100 RPS, its size is already around 56MB, at 200 RPS, its size is 227MB. Doubling the amount of requests increased the data store's size by a factor of almost 4! At 500 RPS, the size grows only slightly, reaching a final value of 232MB. Once again, this indicates a projection lag.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment-database-connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l3_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/enrollment/enrollment-data-size.png}
        \caption{Data Store Size vs. Load}
        \label{fig:l3_data_size}
    \end{subfigure}
    \caption[L3 Database Usage, load measured in \gls{rps}]{L3 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l3}.}
    \label{fig:l3_database}
\end{figure}

These values correspond to the following scalability metric for the CRUD application: $\psi(50, 100)\approx 2.7$; and the following scalability metric for the ES-CQRS application: $\psi(50, 100)\approx 0.2$.

\subsection{Read Performance}

When measuring read performance, no data is created during load generation. Therefore, the visualizations of data store size compared to load are replaced by simple tables, as each test creates the exact same amount of data.

\subsubsection{L4: Read Lectures for Student}
\label{sec:l4}

\texttt{GET} \texttt{/lectures} returns all lectures a student is enrolled or waitlisted in. \autoref{fig:l4_combined} presents client-side and server-side latencies for this endpoint using a logarithmic y-axis.

In the client-side graph (\autoref{fig:l4_latency_vs_load_client}), both applications maintain $latency\_p50$ and $latency\_p95$ of below 10ms up to 3000 \gls{rps}. At 3000 \gls{rps}, the ES-CQRS application exhibits an around 6x higher $latency\_p95$ than the CRUD app. Beyond 3000 \gls{rps}, though, the CRUD latencies overtake the ES-CQRS latencies. At 4000 \gls{rps}, the ES-CQRS application exhibits a $latency\_p95$ of around 370ms, which is around 1.7x faster than  the CRUD application at 620ms and a $latency\_p50$ of 20ms, around a 6x speedup compared to CRUD. Both applications violate \ref{slo-latency} beyond 3000 \gls{rps}.

It should be noted that at 4000 RPS, tests on both applications dropped some iterations with a $dropped\_iterations\_rate$ of roughly 2, meaning about 2 iterations, or about 0.05\% of iterations, were dropped per second. However, this metric exhibits high variance. Because the confidence intervals exceed the mean values, the results for this specific metric are not statistically significant (see \autoref{table:run-read-lectures_client}).

The server-side graph, presented in \autoref{fig:l6_latency_vs_load_server}, initially shows a similar pattern. Once exceeding 3000 \gls{rps}, the latencies also start increasing, however, the observed increase is not as strong as in the client-side latencies. At 4000 \gls{rps}, the ES-CQRS application shows a $latency\_p95$ of around 60ms, the CRUD application has a $latency\_p95$ of around 130ms.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/read-lectures/read-lectures_latency-vs-load_client.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l4_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/read-lectures/read-lectures_latency-vs-load_server.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l4_latency_vs_load_server}
    \end{subfigure}
    \caption[L4 Performance Metrics, load measured in \gls{rps}]{L4 Performance Metrics: Load measured in \gls{rps}. Detailed results in \ref{results:l4}.}
    \label{fig:l4_combined}
\end{figure}

Regarding CPU usage, pictured in \autoref{fig:l4_cpu_usage}, both applications exhibit a linear increase as the load intensifies. Between 25 and 3000 \gls{rps}, the ES-CQRS application consistently maintains a higher median CPU usage compared to the CRUD application, reaching a peak relative difference at 100 \gls{rps} where it is 1.9x higher. As the load reaches 4000 \gls{rps}, the two applications converge at approximately 60\% usage, with the CRUD application showing a slightly higher median of 61\% and a wider confidence interval.

\autoref{fig:l4_threadpool_usage} visualizes the application's threadpool usage. Both applications remain stable at a baseline of 10 threads for loads between 25 and 500 \gls{rps}. As the load increases to 1000 \gls{rps}, the ES-CQRS application begins using more threads, climbing to 47 threads at 2000 \gls{rps} and 158 threads at 3000 \gls{rps}, which is 5.1x higher than the CRUD application at that same point. The CRUD application maintains a lower threadpool usage until it reaches 3000 \gls{rps}. Finally, at the maximum load of 4000 \gls{rps}, both applications reach an identical ceiling of 200 threads.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/read-lectures/read-lectures_cpu_usage.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l4_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/read-lectures/read-lectures_threadpool_usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l4_threadpool_usage}
    \end{subfigure}
    \caption[L4 Resource Usage, load measured in \gls{rps}]{L4 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l4}.}
    \label{fig:l4_resource_usage_cpu}
\end{figure}

Active database connections are visualized in \autoref{fig:l4_db_connections}. Both the CRUD and ES-CQRS applications maintain a median of zero active connections for loads ranging from 25 to 1000 RPS. The CRUD application begins to utilize more connections first, reaching a median of 1 at 2000 RPS and 2 at 3000 RPS. During this same interval, the ES-CQRS application remains at a median of zero connections until 3000 RPS, where it records a median of 1, making it 2x lower than the CRUD application. At the maximum load of 4000 RPS, database connection usage increases for both, with the CRUD application reaching a median of 8 and the ES-CQRS application reaching a median of 6.

In terms of data store size for seed data, shown in \autoref{fig:l4_data_size}, the ES-CQRS application requires significantly more storage than the CRUD application. Specifically, the CRUD application uses around 9MB, while the ES-CQRS application uses around 17MB, a 2x higher storage value.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/read-lectures/read-lectures_db_connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l4_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/run-read-lectures_datastore_size.tex}
        }
        \caption{Data Store Size}
        \label{fig:l4_data_size}
    \end{subfigure}
    \caption[L4 Database Usage, load measured in \gls{rps}]{L4 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l4}.}
    \label{fig:l4_database}
\end{figure}

These values correspond to the following scalability metric for the CRUD application: $\psi(2000, 3000)\approx 0.6$; and the following scalability metric for the ES-CQRS application: $\psi(2000, 3000)\approx 0.3$. TODO: Add 3000 → 4000 RPS.

\subsubsection{L5: Read All Lectures (TODO)}
\label{sec:l5}

The \texttt{GET} \texttt{/lectures/all} endpoint returns a list of all lectures, including details.

Latency here. Most likely, the ES-CQRS app will be faster, which i have shown in local testing.

CPU Usage here.

Database connections here.

\subsubsection{L6: Get Credits}
\label{sec:l6}

The \texttt{GET} \texttt{/stats/credits} endpoint retrieves a student's total collected credits. \autoref{fig:l6_combined} presents the endpoint's client-side and server-side latencies using a logarithmic y-axis.

\autoref{fig:l6_latency_vs_load_client} presents the client-side latency under increasing load. It can be seen that the $latency\_p50$ remains below 5ms for both applications until around 2000 \gls{rps}.

Between 2000 \gls{rps} and 3000 \gls{rps}, a performance divergence occurs: the CRUD application's $latency\_p50$ and $latency\_p95$ increase to more than 1000ms, violating \ref{slo-latency} beyond 2000 \gls{rps}. On the other hand, the ES-CQRS application still exhibits a $latency\_p95$ of less than 10ms at 3000 \gls{rps}. This represents a speedup of around 200x. At 4000 \gls{rps}, the ES-CQRS application exhibits a $latency\_p95$ of around 80ms, a 20x speedup. Beyond 4000 \gls{rps}, the ES-CQRS app's latencies also begin to violate \ref{slo-latency}, reaching latencies around 1000ms.

It can be noted that starting at 3000 \gls{rps}, the CRUD application's latencies seem to reach a plateau, with identical observed latencies at 3000, 4000 and 5000 \gls{rps}. Meanwhile, the ES-CQRS application's latencies keep increasing up to a load of 5000 \gls{rps}. At this load, the ES-CQRS application's $latency\_p95$ is about 2.4x lower than the CRUD application's.

At 3000 RPS, the CRUD application has a $dropped\_iterations\_rate$ of around 360. Until 5000 RPS, the value reaches 1581. Dropping iterations artificially keeps queues on the server shorter, which could explain the observed latency plateau in CRUD. It should also be noted that at 5000 RPS, ES-CQRS begins to drop some iterations with $dropped\_iterations\_rate\approx38$.

The server latencies, displayed in \autoref{fig:l6_latency_vs_load_server}, differ from client latencies at higher loads. Starting at 3000 \gls{rps}, the measured latencies do not increase as strongly as observed on the client. At 5000 \gls{rps}, the $latency\_p95$ of the CRUD app resides around 260ms, while the ES-CQRS app has a $latency\_p95$ of around 50ms.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/get-credits/get-credits-latency-vs-load__client.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l6_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/get-credits/get-credits-latency-vs-load__server.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l6_latency_vs_load_server}
    \end{subfigure}
    \caption[L6 Performance Metrics, load measured in \gls{rps}]{L6 Performance Metrics: Load measured in \gls{rps}. Detailed results in \ref{results:l6}.}
    \label{fig:l6_combined}
\end{figure}

\autoref{fig:l6_cpu_usage} shows CPU usage of both applications from 25 to 4000 \gls{rps}. At the lowest load of 25 \gls{rps}, both applications exhibit a median $cpu\_usage$ close to 0. As the load increases to 1000 \gls{rps}, the CRUD median reaches around 21\% compared to $\approx$17\% for ES-CQRS. At 2000 \gls{rps}, the gap widens with CRUD at 45\% and ES-CQRS at 35\%, a 1.3x lower value for ES-CQRS. Both applications peak near 4000 \gls{rps}, where CRUD records 56\% and ES-CQRS records 57\%. The \gls{iqr} remains narrow for both applications across most data points.

Threadpool usage is visualized in \autoref{fig:l6_threadpool_usage}. From 25 to 500 \gls{rps}, both CRUD and ES-CQRS maintain a constant median threadpool usage of 10. At 1000 \gls{rps}, the values begin to diverge, with CRUD at 11 and ES-CQRS at 16. At 2000 \gls{rps}, CRUD usage rises to 36 while ES-CQRS is at 31. An increase occurs at 3000 \gls{rps}, where CRUD reaches a median of 200 utilized threads, while ES-CQRS reaches 123. By 4000 \gls{rps}, both applications reach a maximum median value of 200. The graph shows a wide \gls{iqr} for ES-CQRS at 3000 \gls{rps}. In contrast, CRUD has a very tight \gls{iqr} beyond 3000 \gls{rps}, indicating that the median of 200 utilized threads remains constant across most runs.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/get-credits/get-credits-cpu-usage.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l6_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/get-credits/get-credits-threadpool-usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l6_threadpool_usage}
    \end{subfigure}
    \caption[L6 Resource Usage, load measured in \gls{rps}]{L6 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l6}.}
    \label{fig:l6_resource_usage_cpu}
\end{figure}

\autoref{fig:l6_database} illustrates the median number of active database connections under increasing load. Until 500 \gls{rps}, both applications maintain a value of 0. Beyond 500 \gls{rps}, the CRUD application's value increases, reaching a ceiling of 10 active connections at 3000 \gls{rps}. In contrast, the ES-CQRS application's value starts rising linearly only at 2000 \gls{rps}, reaching its maximum of 2 active connections at 4000 \gls{rps}, with an \gls{iqr} spanning from 0 to 6.

The size of the data store is presented in \autoref{fig:l6_data_size}. At 19.6MB, the ES-CQRS application uses twice as much storage to store the seed data than the CRUD application, which uses around 9.6MB.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/get-credits/get-credits-db-connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l6_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/run-get-credits_datastore_size.tex}
        }
        \caption{Data Store Size}
        \label{fig:l6_data_size}
    \end{subfigure}
    \caption[L6 Database Usage, load measured in \gls{rps}]{L6 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l6}.}
    \label{fig:l6_database}
\end{figure}

These values correspond to the following scalability metrics for the CRUD application: $\psi(1000, 2000)\approx 0.4$, $\psi(2000, 3000)\approx 0.00$; and the following scalability metrics for the ES-CQRS application: $\psi(1000, 2000)\approx 1.1$, $\psi(2000, 3000)\approx 0.3$.

\subsection{Time to Consistency / Freshness}

\ref{slo-freshness} defined a threshold of 100ms inside which all writes shall be reflected on the read-side. This "freshness" is measured in the following test.

\subsubsection{L7: Create Lecture, then Read}
\label{sec:l7}

This load test differs from others in the fact that each iteration executes 2 \gls{http} requests. The first request creates a lecture. After sleeping for 100ms --- the consistency threshold defined in \ref{slo-freshness} --- the script executes a request to \texttt{GET} the created lecture. If status code $404$ is returned, the write was not reflected in the read model in time. The rate of successful reads is recorded as a metric called $read\_visible\_rate$, presented in \autoref{fig:l7_read_visible_rate}. It can be seen that once exceeding 200 \gls{ips}, the ES-CQRS application failed to synchronize the read-side fast enough. \autoref{fig:l7_latency_vs_load} shows the latencies under varying loads using a logarithmic y-axis. $latency\_p50$ remains similar for both applications, however the ES-CQRS application's $latency\_p95$ increases with rising \gls{ips}, finally violating the threshold of 100ms defined in \ref{slo-latency} once exceeding 400 \gls{ips}.

The CRUD application consistently maintains a 100\% $read\_visible\_rate$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/get_lecture_latency-vs-load__client.png}
        \caption{Latency vs. Load, visualized for the subsequent GET request}
        \label{fig:l7_latency_vs_load}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/get_lecture-read-visible-rate.png}
        \caption{Rate of visible reads}
        \label{fig:l7_read_visible_rate}
    \end{subfigure}
    \caption{L7 Performance Metrics, load measured in \gls{ips} with 2 requests per iteration. Detailed results in \ref{results:l7}}
    \label{fig:l7_combined}
\end{figure}

$cpu\_usage$ of both applications is plotted in \autoref{fig:l6_cpu_usage}. A linear increase in usage can be observed in both cases, with the ES-CQRS application consistenly utilizing more CPU. At the final tested load of 500 \gls{rps}, ES-CQRS reaches a value above 40\%, while CRUD utilizes around 16\%.

Threadpool usage of both applications is visualized in \autoref{fig:l6_threadpool_usage}. In both cases, the value remains very close to the base value of 10. Beyond 200 \gls{rps}, ES-CQRS starts to use more threads, reaching a utilization of 100 threads at 400 \gls{rps}, and reaching the ceiling of 200 threads at the final tested load of 500 \gls{rps}. CRUD remains below 20 utilized threads consistently.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/time-to-consistency-CPU-Usage.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l7_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/time-to-consistency-Threadpool-Usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l7_threadpool_usage}
    \end{subfigure}
    \caption[L7 Resource Usage, load measured in \gls{rps}]{L7 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l7}.}
    \label{fig:l7_resource_usage_cpu}
\end{figure}

Active database connections are visualized in \autoref{fig:l6_db_connections}. Both the CRUD and ES-CQRS applications maintain a median of zero active connections for loads up to 100 \gls{rps}, though the \gls{iqr} shows that ES-CQRS uses some database connections. At 200 RPS, both applications use a median of 1 database connections. CRUD stays at this level until 500 RPS, where it utilizes 2 connections. ES-CQRS, in contrast, begins claiming more connections, reaching a final value of 5 at 500 RPS.

In terms of data store size, shown in \autoref{fig:l6_data_size}, ES-CQRS again utilizes more storage. Both applications show a linear increase. The CRUD application shows a final data store size of around 46MB. This comes out to $\approx$1kB per created lecture. ES-CQRS reaches its peak at 400 \gls{rps} with a value of 60MB, around 1.5kB per lecture --- 1.6x higher than CRUD. However, at 500 \gls{rps}, the storage size drops slightly, indicating a projection lag.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/time-to-consistency-DB-Connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l7_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/time-to-consistency/time-to-consistency-data_size.png}
        \caption{Data Store Size vs. Load}
        \label{fig:l7_data_size}
    \end{subfigure}
    \caption[L7 Database Usage, load measured in \gls{rps}]{L7 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l7}.}
    \label{fig:l7_database}
\end{figure}

These values correspond to the following scalability metric for the CRUD application: $\psi(300, 400)\approx 1.2$; and the following scalability metric for the ES-CQRS application: $\psi(300, 400)\approx 0.3$. It should be noted that the latency used for calculation was the sum of both requests' $latency\_p95$.

\subsection{Historic Reconstruction}
\label{sec:results-historic-reconstruction}

This subsection presents load tests which evaluate the performance of endpoints reconstructing historical state.

\subsubsection{L8: Grade History}
\label{sec:l8}

The endpoint \texttt{GET} \texttt{/stats/grades/history} returns the historical states of a grade. Its client-side and server-side latencies are presented in \autoref{fig:l6_combined}. Up to a load of 1000 \gls{rps}, both applications maintain a sub-10ms $latency\_p50$ and $latency\_p95$. Beyond that point, though, the ES-CQRS application's latencies increase sharply, reaching values above 1000ms. This marks the point at which the ES-CQRS application fails \ref{slo-latency}. The CRUD application, on the other hand, remains at a $latency\_p95$ of just around 2ms at the final tested load of 2000\gls{rps}.

The server latencies, visualized in \autoref{fig:l8_latency_vs_load_server}, paint a similar picture. The CRUD application's server-side response times stay at around 1ms, while the ES-CQRS application's response time increases to over 100ms at 2000 \gls{rps}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/grade-history/grade-history-latency-vs-load-CLIENT.png}
        \caption{Latency vs. Load measured on the client}
        \label{fig:l8_latency_vs_load_client}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/grade-history/grade-history-latency-vs-load-SERVER.png}
        \caption{Latency vs. Load measured on the server}
        \label{fig:l8_latency_vs_load_server}
    \end{subfigure}
    \caption{L8 Performance Metrics, load measured in \gls{rps}. Detailed results in \ref{results:l8}}
    \label{fig:l8_combined}
\end{figure}

The applications' $cpu\_usage$ is depicted in \autoref{fig:l8_cpu_usage}. Both implementations exhibit a linear growth, with the CRUD application reaching its maximum at around 23\% and ES-CQRS reaching a maximum $cpu\_usage$ of 51\%, which is a 2.2x increase.

$tomcat\_threads$ is visualized in \autoref{fig:l8_threadpool_usage}. Both applications show a similar thread usage up to 1000 \gls{rps}, staying below a median value of 25. At 2000 \gls{rps}, the ES-CQRS application uses a median of 200 threads, with a wide \gls{iqr} reaching from around 40 to 200. The CRUD application stays at a median thread utilization of 25.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/grade-history/grade-history-cpu-usage.png}
        \caption{Resource Usage (\%) vs. Load}
        \label{fig:l8_cpu_usage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/grade-history/grade-history-threadpool-usage.png}
        \caption{Threadpool Usage vs. Load}
        \label{fig:l8_threadpool_usage}
    \end{subfigure}
    \caption[L8 Resource Usage, load measured in \gls{rps}]{L8 Resource Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l8}.}
    \label{fig:l8_resource_usage_cpu}
\end{figure}

\autoref{fig:l8_db_connections} shows the median number of utilized database connections --- $hikari\_connections$ --- under increasing load. Up to 1000 \gls{rps}, both applications show identical behavior, staying at a median of 0 until 500 \gls{rps}, before increasing to 1 at 1000 \gls{rps}. Afterward, however, the ES-CQRS application shows a sharp increase, reaching a median of 10 at 2000 \gls{rps} with a wide \gls{iqr} spannin from 4 to 10. At this load, the CRUD application still remains at a median of 1.

\autoref{tab:l8_data_size} shows the storage taken up by the test's seed data. The ES-CQRS application takes up twice the amount of storage at $\approx$19.7MB, while CRUD uses around 9.8MB.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/results/grade-history/grade-history-db-connections.png}
        \caption{Database Connections vs. Load}
        \label{fig:l8_db_connections}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \small
        \input{tables/run-grade-history_datastore_size.tex}
        \caption{Data Store Size}
        \label{tab:l8_data_size}
    \end{subfigure}
    \caption[L8 Database Usage, load measured in \gls{rps}]{L8 Database Usage: Load measured in \gls{rps}. Detailed results in \ref{results:l8}.}
    \label{fig:l8_database}
\end{figure}

These values correspond to the following scalability metrics for the CRUD application: $\psi(500, 1000)\approx 2.0$, $\psi(1000, 2000) \approx 1.3$; and the following scalability metrics for the ES-CQRS application: $\psi(500, 1000) \approx 1.2$, $\psi(1000, 2000) \approx 0.00$.

\section{Static Analysis}
\label{sec:statc-analysis-results}

\acrshort{rq} 2 attempts to evaluate the architectural flexibility of the architectural styles \gls{crud} and \gls{es}-\gls{cqrs}. In \autoref{sec:flexibility-architectural-metrics}, several static analysis methods were established. This section presents results and visualizations for these metrics.

\subsection{Graphs}
\label{sec:static-graphs}

Boxplots are used to visualize the results of static analysis. They are a standardized way of displaying the distribution of data based on a five-number summary: minimum, first quartile (25th \gls{percentile}), \gls{median}, third quartile (75th \gls{percentile}), and maximum. The central box represents the \gls{iqr}, which encompasses the middle 50\% of data points. The \emph{whiskers} extend from the edges of the box to indicate the variability outside the upper and lower quartiles, showing the full range of the data excluding extreme values. Finally, individual points plotted beyond the whiskers are outliers, representing data points that fall further from the median than the rest of the population.

\subsection{Coupling Metrics}
\label{sec:results-coupling}

Afferent coupling ($C_a$, describing incoming connections) and Efferent coupling ($C_e$, describing outgoing connections), which were described in \autoref{sec:coupling-metrics}, are calculated by MetricsReloaded on a package-basis. The results are visualized in a boxplot. Package size influences the value of $C_a$ and $C_e$, which is why the results were normalized by class count. Therefore, the plots show this data:

\begin{equation}
    C_a\_norm = \frac{C_a}{Class\_count}
    \label{eq:c_a_normalized}
\end{equation}


\begin{equation}
    C_e\_norm = \frac{C_e}{Class\_count}
    \label{eq:c_e_normalized}
\end{equation}

\autoref{fig:combined_ca} presents the normalized $C_a$ per application. The CRUD application generally has higher Afferent coupling across its packages (a 33\% higher median and higher 75th \gls{percentile}). Most packages in the ES-CQRS architecture have low Afferent coupling, but some packages areas are more coupled than any package found in the CRUD app.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Ca_normalized_Afferent_Coupling_per_package.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/ca_norm.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $C_a$ (Afferent coupling) by Application.}
    \label{fig:combined_ca}
\end{figure}

Regarding Efferent coupling, the two architectures show more similarity. The medians are almost equal at values of 2.1 (CRUD) and 2.5 (ES-CQRS). CRUD's \gls{iqr} is wider, ranging from 0 to around 13, while the ES-CQRS \gls{iqr} ranges from 0 to around 9. However, the ES-CQRS architecture displays more outliers (7, versus 2 in CRUD) reaching a value of 148, while the maximum value of the CRUD architecture is 92.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Ce_normalized_Efferent_Coupling_per_package.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/ce_norm.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $C_e$ (Efferent coupling) by Application.}
    \label{fig:combined_ce}
\end{figure}

\subsection{Instability and Abstractness}

Instability $I$ is defined as the ratio of Efferent coupling to the total coupling of a package, as shown in \autoref{eq:instability}. Therefore, it can take values between 0 and 1. It is visualized using a boxplot in \autoref{fig:instability}. The plot highlights a wide \gls{iqr} and a median value around 0.5 to 0.6 for both architectures.

Abstractness $A$ measures the ratio of abstract classes and interfaces to the total number of classes in a package, as presented in \autoref{eq:abstractness}. Therefore, it can take values between 0 and 1. Its visualization in \autoref{fig:abstractness} shows that the typical package in both applications has an Abstractness of 0. The \gls{iqr} of the CRUD architecture reaches from 0 to 0.2; the \gls{iqr} of the ES-CQRS architecture reaches from 0 to $0.4$.

\autoref{fig:main-sequence} shows a scatter plot which visualizes $A$ and $I$, as well as the "Main Sequence" (gray diagonal line). The concept of the "Main Sequence" was explained in \autoref{sec:instability}. The distribution shows two prominent large clusters of the ES-CQRS architecture located at the corners of (0, 0) and (1, 0), while the remaining smaller points are scattered primarily in the lower half of the graph below the diagonal line. Generally, it can be seen that ES-CQRS has more packages than CRUD and is more abstract. The ES-CQRS architecture exhibits a slightly lower median Distance from the Main Sequence $D$ (\autoref{fig:distance-main-sequence-per-package}) with a value of around 0.4, opposed to around 0.5 for the CRUD architecture. However, both \glspl{iqr} for $D$ have a wide spread, with the ES-CQRS architecture spanning from 0.1 to almost~1.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Instability_per_package.png}
        \caption{Instability per package. Descriptive statistics in \autoref{table:instability}.}
        \label{fig:instability}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Abstractness_per_package.png}
        \caption{Abstractness per package. Descriptive statistics in \autoref{table:abstractness}.}
        \label{fig:abstractness}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Distance_main_sequene_per_package.png}
        \caption{Distance from the main sequence per package. Descriptive statistics in \autoref{table:distance-from-the-main-sequence}.}
        \label{fig:distance-main-sequence-per-package}
    \end{subfigure}
    \par\medskip
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Martin_main_sequence_graph.png}
        \caption{Visualization of the Main Sequence}
        \label{fig:main-sequence}
    \end{subfigure}
    \caption[Comparison of Instability $I$ and Abstractness $A$.]{Comparison of Instability $I$ and Abstractness $A$. Detailed results in \autoref{appendix:instability-abstractness}.}
    \label{fig:combined_instability_abstractness}
\end{figure}

\subsection{Dependency Metrics}
\label{sec:results-dependency}

\autoref{table:dependency-metrics} outlined all dependency metrics recorded in the applications. In this section, these metrics are visualized using boxplots and descriptive statistics. Per-class results for the described dependency metrics are available in \autoref{appendix:dependency}.

\autoref{fig:combined_dpt} illustrates the distribution of $Dpt$, the number of classes depending directly on a class (\emph{dependents}), for both architectures. Both architectures have an equal median at 2. This indicates that in both cases, a typical class has two dependents. The range between the 25th to 75th \gls{percentile}, also called \gls{iqr} is indicated by the shaded areas. It differs for the two architectures. The CRUD architecture shows that 50\% of classes have 1 to 3 dependents, while the ES-CQRS architecture exhibits higher variability. Its IQR spans from 0 to 4. Notably, since the 25th percentile aligns with the minimum value of 0, at least 75\% of the classes in this architecture have 4 or fewer dependents.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_DPT.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{ % Resizes table to fit subfigure width
            \input{tables/dpt.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $Dpt$ (direct dependants) by Application.}
    \label{fig:combined_dpt}
\end{figure}

$Dpt^*$, the transitive dependent count, is presented in \autoref{fig:combined_dpt_transitive}. Compared to $Dpt$, a larger difference between the architectures is visible. While the median values of both applications are still similar, with values between 2 and 4, the CRUD architecture's \gls{iqr} has a much wider range than the ES-CQRS architecture. 50\% of classes in the CRUD architecture have between 2 and 33 transitive dependents, while at least 75\% of the ES-CQRS architecture's classes have between 0 and 7 transitive dependents.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_DPT-transitive.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{ % Resizes table to fit subfigure width
            \input{tables/dpt_transitive.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $Dpt^*$ (transitive dependants) by Application.}
    \label{fig:combined_dpt_transitive}
\end{figure}

\autoref{fig:combined_dcy} illustrates the distribution of $Dcy$, a metric representing the number of classes a given class directly depends on (\emph{dependencies}). Similar to the results for $Dpt$, the direct dependencies across both architectures exhibit similar values. CRUD and ES-CQRS architecture exhibit a median $Dcy$ of 2, respectively 1, with both \glspl{iqr} situated between 0 and 4. Both architectures feature several outliers, with individual classes reaching direct dependency counts of approximately 40.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_DCY.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/dcy.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $Dcy$ (direct dependencies) by Application.}
    \label{fig:combined_dcy}
\end{figure}

A more pronounced divergence is visible in the transitive dependencies, $Dcy^*$, presented in \autoref{fig:combined_dcy_transitive}. In the CRUD architecture, this distribution shows a much wider range, with the \gls{iqr} sitting between 1 and 26 transitive dependencies.

The ES-CQRS architecture exhibits a more concentrated distribution. Its \gls{iqr} is narrower, with at least 75\% of classes having between 0 and 3 transitive dependencies. While there are numerous outliers reaching more than 40 transitive dependencies, the primary distribution remains lower than that of the CRUD application.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_DCY-transitive.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/dcy_transitive.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $Dcy^*$ (transitive dependencies) by Application.}
    \label{fig:combined_dcy_transitive}
\end{figure}

$PDpt$, presented in \autoref{fig:combined_PDpt}, is a metric describing the number of packages transitively depending on a class. Both architectures have a median value of 1 and a P75 of 2, indicating that at least 75\% of classes have less than 2 transitive package dependents.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_PDpt.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/PDpt.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $PDpt$ (transitive package dependents) by Application.}
    \label{fig:combined_PDpt}
\end{figure}

The $PDcy$ metric describes the number of packages a class transitively depends on. It is presented in \autoref{fig:combined_PDcy}. Again, both architectures show similar values with a median of 1.5 for the CRUD architecture and 1 for ES-CQRS. The \gls{iqr} ranges from $\approx1$ to $\approx3$ for CRUD, and from 0 to 2 for ES-CQRS. The ES-CQRS architecture exhibits more outliers at 7 with a maximum value of 13, while the CRUD application shows one outlier depending on 8 packages.

\begin{figure}[H]
    \centering
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/class_dependencies_PDcy.png}
        \caption{Boxplot distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.48\textwidth}
        \centering
        \small
        \resizebox{\textwidth}{!}{
            \input{tables/PDcy.tex}
        }
        \caption{Descriptive statistics}
    \end{subfigure}
    \caption{Comparison of $PDcy$ (transitive package dependencies) by Application.}
    \label{fig:combined_PDcy}
\end{figure}

\subsection{MOOD Metrics}
\label{sec:results-mood}

Results of the \acrfull{mood} suite, outlined in \autoref{sec:mood}, are presented in \autoref{fig:mood-results}. \gls{ahf} is the highest value for both architectures. Both architectures sit at around 95\%.

The CRUD architecture exhibits a \gls{mif} of around 16\%, higher than the ES-CQRS architecture at 1\%. With a value of 45\%, the ES-CQRS architecture's \gls{mhf} is higher than the 29\% for the CRUD architecture.

The CRUD architecture's \gls{cf} sits at around 12\%, while the ES-CQRS's architecture's \gls{cf} has a value of around 3\%.

The \gls{aif} of the CRUD architecture is at around 28\%, the ES-CQRS application reaches 8\%.

Generally, the CRUD Architecture covers a larger total surface area on the diagram, specifically showing higher values on the \gls{aif} and \gls{cf} axes compared to the ES-CQRS Architecture.

It is worth noting that the \gls{pf} of both architectures is not present in the diagram. This is due to the fact that the values exceed 100\%, with the CRUD architecture having a \gls{pf} of 360\%, and the ES-CQRS architecture having a \gls{pf} of 185\%. The \gls{pf} calculates the ratio of polymorphic situations to the maximum possible number of polymorphic situations, but the static analysis tool used does not take classes from libraries or external modules into consideration when computing the total possible number, which is why the values exceed 100\%.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{images/static-analysis/MOOD_spider_diagram.png}
    \caption{MOOD metrics presented in a spider diagram. Results in \ref{table:mood}}
    \label{fig:mood-results}
\end{figure}

% \subsection{Complexity Metrics}
% \label{sec:results-complexity}

% Commented out: Ergebnisse sind sehr nichtssagend. In Methodik ebenfalls auskommentiert. 

\subsection{Chidamber Kemerer Metrics}

In \autoref{sec:ck-metrics}, the \acrlong{ck} suite was described. Its results are presented in \autoref{fig:ck-results} using a spider diagram. As the metrics are calculated on a per-class basis, the values were normalized and aggregated using a median and a mean for visualization purposes.

\autoref{fig:ck_median} shows the median values of the metrics. The CRUD architecture's plot (blue) forms the larger shape. It reaches the highest point on the \gls{cbo} axis, with a value around 0.1, and the \gls{dit} axis with a value around 0.13. It also shows a distinct outward point on the \gls{rfc} axis.

The ES-CQRS architecture's plot forms a smaller shape nested mostly inside the blue area. It shows lower values than the CRUD architecture on the \gls{cbo} (0.07), \gls{wmc} (0), and \gls{rfc} (< 0.05) axes. It sits close to the CRUD architecture on the \gls{lcom} and \gls{dit} axes. While the median \gls{wmc} of ES-CQRS sits at a value of 0, the mean (\autoref{fig:ck_mean}) shows a value of about 0.02.

Both architectures exhibit a median \gls{noc} of 0. However, \autoref{fig:ck_mean} reveals that some polymorphism exists in the CRUD application.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Median-c-k-metrics.png}
        \caption{Median CK-Metrics}
        \label{fig:ck_median}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/static-analysis/Mean-c-k-metrics.png}
        \caption{Mean CK Metrics}
        \label{fig:ck_mean}
    \end{subfigure}
    \caption[CK-Metrics presented in spider diagrams]{CK-Metrics presented in spider diagrams. Detailed results in \ref{appendix:ck-results}}
    \label{fig:ck-results}
\end{figure}
