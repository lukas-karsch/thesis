\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[automake]{glossaries}
\usepackage{array}
\usepackage[table]{xcolor}

\usepackage{color}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}
\definecolor{porange}{rgb}{1,0.5,0.1}

\usepackage{listings}
\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  columns=flexible,
  commentstyle=\color{pgrey},
  keywordstyle=\color{porange},
  stringstyle=\color{pgreen},
  basicstyle={\ttfamily\small},
  moredelim=[il][\textcolor{pgrey}]{\$\$},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}

\usepackage[
  backend=biber,
  style=authoryear, % or numeric, ieee, apa, ...
]{biblatex}
\DefineBibliographyStrings{english}{
  and = {\&}
}

\usepackage{hyperref}

\addbibresource{references.bib}

\makeglossaries

\newglossaryentry{api}
{
    name=API, 
    description={API stands for \emph{Application Programming Interface}. It describes the public interface of a module or service, often exposed over a network}
}

\newglossaryentry{rest}
{
    name=REST,
    description={REST stands for \emph{Representational State Transfer}. It is an architectural style for distributed hypermedia systems}
}

\newglossaryentry{http}
{
    name=HTTP,
    description={HTTP stands for \emph{Hypertext Transfer Protocol}. It is a protocol used in internet communication and was defined in RFC 2616 \parencite{rfc2616}}
}

\newglossaryentry{adm}
{
    name={Anemic Domain Model},
    description={The objects describing the domain only hold data, no logic}
}

\newglossaryentry{rdm}
{
    name={Rich Domain Model},
    description={Objects incorporate both data and the behavior or rules that govern that data}
}

\newglossaryentry{atomicity}
{
    name=Atomicity,
    description={Atomicity means that an action is either fully executed or not at all. Atomic operations make sure the application is not left in an invalid state \parencite[10]{bernstein_principles_2009}}
}

\newglossaryentry{cap}
{
    name={CAP Theorem},
    description={The CAP theorem by Eric Brewer states that a distributed data store can only display at most two of the following three guarantees at the same time: consistency, availability and partition tolerance \parencite{gilbert_brewers_2002}}
}

\newglossaryentry{contract-test}
{
    name={Contract Test},
    text={contract test},
    plural={contract tests},
    description={A contract test verifies that services implement a shared interface by testing their interactions against an explicitly defined contract}
}

\newglossaryentry{groovy}
{
    name=Groovy,
    description={A dynamic JVM language that extends Java with concise syntax and powerful features such as closures, making it well suited for scripting, DSLs, and test code \parencite{groovy-homepage}}
}

\newglossaryentry{gpath}
{
    name={GPath Expression},
    text={GPath expression},
    plural={GPath expressions},
    description={A Groovy-based path language for navigating and querying nested object graphs (such as JSON or XML) using concise, expressive selectors and closures  \parencite{groovy-gpath}}
}

\newglossaryentry{testcontainer}
{
    name=Testcontainer,
    description={Testcontainers are a way to declare infrastructure dependencies as code using Docker \parencite{testcontainers-homepage}}
}

\newacronym{www}{WWW}{World Wide Web}

\newacronym{hateoas}{HATEOAS}{Hypermedia as the engine of application state}

\newacronym{html}{HTML}{HyperText Markup Language}

\newacronym{json}{JSON}{JavaScript Object Notation}

\newacronym{xml}{XML}{Extensible Markup Language}

\newacronym{dao}{DAO}{Data Access Object}

\newacronym{ddd}{DDD}{Domain Driven Design}

\newacronym[plural=URIs]{uri}{URI}{Uniform Resource Identifier}

\newacronym{crud}{CRUD}{Create Read Update Delete}

\newacronym{dto}{DTO}{Data Transfer Object}

\newacronym{acid}{ACID}{Atomicity, Consistency, Isolation, Durability}

\newacronym{cqrs}{CQRS}{Command Query Responsibility Segregation}

\newacronym{cqs}{CQS}{Command And Query Separation}

\newacronym{base}{BASE}{Basically Available, Soft State, Eventual Consistency}

\newacronym{es}{ES}{Event Sourcing}

\newacronym{dsl}{DSL}{Data Specific Language}

\begin{document}

\title{How does an Event Sourcing architecture compare to CRUD systems with an independent audit log, when it comes to scalability, performance and traceability?}
\author{Lukas Karsch}

\begin{titlepage}
    \centering

    \includegraphics[width=0.3\textwidth]{images/HdM_Logo.svg.png}
    \vspace{1cm}

    {\large Bachelor's Thesis in Computer Science and Media}

    \vspace{1.5cm}

    % Title
    {\LARGE\bfseries How does an Event Sourcing architecture compare to CRUD systems with an independent audit log, when it comes to scalability, performance and traceability?}

    \vspace{0.5cm}
    \rule{\linewidth}{0.5pt}
    \vspace{0.5cm}

    {\large\bfseries Lukas Karsch}

    \vspace{0.3cm}

    45259

    \vspace{0.8cm}

    %LTeX: language=de-DE
    {\bfseries Hochschule der Medien Stuttgart}
    %LTeX: language=en-US

    \vspace{0.8cm}

    Submitted on 2026/03/02

    \vspace{0.3cm}

    to obtain the degree of Bachelor of Science

    \vfill

    \begin{flushleft}
        \begin{tabular}{ll}
            \textbf{Main Supervisor:}      & Prof. Dr. Tobias Jordine \\[0.3cm]
            \textbf{Secondary Supervisor:} & Felix Messner            \\[0.3cm]
        \end{tabular}
    \end{flushleft}

\end{titlepage}

\newpage

%LTeX: language=de-DE
\section*{Ehrenwörtliche Erklärung}
%LTeX: language=en-US

\newpage

\tableofcontents

\newpage

\section{Introduction}

\subsection{Motivation}

\subsection{Research question(s)}

\subsection{Goals and non goals}

\subsection{Structure of the paper}

\section{Basics}

\subsection{WWW, Web APIs, REST}

The \acrfull{www} is a connected information network used to exchange data. Resources are can be accessed via \glspl{uri} which are transferred using formats like JSON or HTML via protocols like \gls{http}. HTTP is a stateless protocol based on a request-response structure. It supports standardized request types, such as \texttt{GET} and \texttt{POST}, which convey a semantic meaning \parencite{jacobs_architecture_2004}.

Web APIs are interfaces that enable applications to communicate. They use HTTP as a network-based API \parencite[138]{fielding_architectural_2000}. Modern APIs typically follow \gls{rest} principles. REST stands for "Representational State Transfer" and describes an architectural style for distributed hypermedia systems \parencite[76]{fielding_architectural_2000}.

REST APIs adhere to principles derived from a set of constraints imposed by the HTTP protocol, for example. One such constraint is "stateless communication": Communication between clients and the server must be \emph{stateless}, meaning the client must provide all the necessary information for the server to fully understand the request.

Furthermore, every resource in REST applications must be addressable via a unique ID, which can then be used to derive a \acrshort{uri} to access the resource. Below are some examples for resources and \glspl{uri} which could be derived from them:

\begin{itemize}
    \item Book; ID=1; URI=\texttt{http://example.com/books/1}
    \item Book; ID=2; URI=\texttt{http://example.com/books/2}
    \item Author; ID=100; URI=\texttt{http://example.com/authors/100}
\end{itemize}

The "\acrfull{hateoas}" principle states that resources should be linked to each other. Clients should be able to control the application by following a series of links provided by the server \parencite{tilkov_brief_2007}.

Every resource must support the same interface, usually HTTP methods (GET, POST, PUT, etc.) where operations on the resource correspond to one method of the interface. For example, a POST operation on a customer might map to the \texttt{createCustomer()} operation on a service.

Resources are decoupled from their representations. Clients can request different representations of a resource, depending on their needs \parencite{tilkov_brief_2007}: a web browser might request \acrshort{html}, while another server or application might request \acrshort{xml} or \acrshort{json}.

%s TODO explain CRUD here or somewhere else? 

\subsection{Layered Architecture Foundations}
\label{sec:layered}

Layered Architecture is the most common architecture pattern in enterprise applications. Applications following a layered architecture are divided into \emph{horizontal layers}, with each layer performing a specific role. A standard implementation consists of the following layers:

\begin{itemize}
    \item Presentation: Handles requests and displays data in a user interface or by turning it into representations (e.g. JSON)
    \item Business: Encapsulates business logic
    \item Persistence: Persists data by interacting with the underlying persistence technologies (e.g. SQL databases)
    \item Database
\end{itemize}

A key concept in this design is layers of isolation, where layers are "closed", meaning a request must pass through the layer directly below it to reach the next, ensuring that changes in one layer do not affect others.

In a layered application, data flows downwards during request handling and upwards during the response: a request arrives in the presentation layer, which delegates to the business layer. The business layer fetches data from the persistence layer which holds logic to retrieve data, e.g. by encapsulating SQL statements.

The database responds with raw data, which is turned into a \acrlong{dao} by the persistence layer. The business layer uses this data to execute rules and make decisions. The result will be returned to the presentation layer which can then wrap the response and return it to the caller. \parencite{richards_software_2015}

The data in layered applications is often times modeled in an \emph{anemic} way. In an \gls{adm}, business entities are treated as only data. They are objects which contain no business logic, only getters and setters. Business logic is entirely contained in the business (or "service") layer. \textcite{anemic-fowler-2003} describes this as an object-oriented \emph{antipattern}.

% TODO figure

\subsection{Domain Driven Design}
\label{sec:ddd}

\acrfull{ddd} is a different architectural approach for applications.  It differs from layered architecture primarily in the way the domain is modelled and the responsibilities of application services.

The core idea of \acrshort{ddd} is that the primary focus of a software project should not be the underlying technologies, but the domain. The domain is the topic with which a software concerns itself. The software design should be based on a model that closely matches the domain and reflects a deep understanding of business requirements. \parencite[8, 12]{evans_domain-driven_2004}

This domain model is built from a \emph{ubiquitous language} which is a language shared between domain experts and software experts. This ubiquitous language is built directly from the real domain and must be used in all communications regarding the software. \parencite[24-26]{evans_domain-driven_2004}

%s TODO here, talk about model driven design -> way from the language to the code 

The software must always reflect the way that the domain is talked about. Changes to the domain and the ubiquitous language must result in an immediate change to the domain model.

When modeling the domain model, the aim should not be to create a perfect replica of the real world. While it should carefully be chosen, the domain model artificial and forms a selective abstraction which should be chosen for its utility. \parencite[12, 13]{evans_domain-driven_2004}

While \hyperref[sec:layered]{Layered Architecture} organizes code into technical tiers and is typically built on \glspl{adm}, often resulting in the \emph{big ball of mud} antipattern \parencite[V]{richards_software_2015}, \acrshort{ddd} demands a \gls{rdm} where objects incorporate both data and the behavior or rules that govern that data. The code is structured semantically into bounded context and modules which are chosen to tell the "story" of a system rather than its technicalities. \parencite[80]{evans_domain-driven_2004}

Entities (also known as reference objects) are domain elements fundamentally defined by a thread of continuity and identity rather than their specific attributes. Entities must be distinguishable from other entities, even if they share the same characteristics. To ensure consistency and identity, a unique identifier is assigned to entities. This identifier is immutable throughout the object's life. \parencite[65-69]{evans_domain-driven_2004}

Value Objects are elements that describe the nature or state of something and have no conceptual identity of their own. They are interesting only for their characteristics. While two entities with the same characteristics are considered as different from each other, the system does not care about "identity" of a value object, since only its characteristics are relevant. Value objects should be used to encapsulate concepts, such as using an "Address" object instead of distinct "Street" and "City" attributes. Value objects should be immutable. They are never modified, instead they are replaced entirely when a new value is required. \parencite[70-72]{evans_domain-driven_2004}

Using a \gls{rdm} does not mean that there should be no layers, the opposite is the case. \textcite{evans_domain-driven_2004} advocates for using layers in domain driven designs. He proposes the following layers: \parencite[53]{evans_domain-driven_2004}

\begin{itemize}
    \item Presentation: Presents information and handles commands
    \item Application Layer: Coordinates app activity. Does not hold business logic, but delegate tasks and hold information about their progress
    \item Domain Layer: Holds information about the domain. Stateful objects (rich domain model) that hold business logic and rules
    \item Infrastructure layer: Supports other layers. Handles concerns like communication and persistence
\end{itemize}

\textcite[75]{evans_domain-driven_2004} points out that in some cases, operations in the domain can not be mapped to one object. For example, transferring money does conceptually not belong to one bank account. In those cases, where operations are important domain concepts, domain services can be introduced as part of model-driven design. To keep the domain model rich and not fall back into procedural style programming like with \gls{adm}, it is important to use services only when necessary. Services are not allowed to strip the entities and value objects in the domain of behavior. According to Evans, a good domain service has the following characteristics:

\begin{itemize}
    \item The operation relates to a domain concept which would be misplaced on an entity or a value object
    \item The operation performed refers to other objects in the domain
    \item The operation is stateless
\end{itemize}

\subsection{CRUD architecture}

% TODO refine 

\hyperref[sec:layered]{Layered architectures} are the standard for data-oriented enterprise applications. These applications mostly follow a \acrshort{crud} architecture. \acrshort{crud} is an acronym coined by \textcite{martin_managing_1983} that stands for "Create, Read, Update, Delete". These four actions can be applied to any record of data.

The state of domain objects in a \acrshort{crud} architecture is often mapped to normalized tables on a relational database, though other storage mechanisms maybe used. The application acts on the current state of the data, with all actions (reads and writes) acting on the same data. % TODO cite 

\acrshort{acid} (\acrlong{acid}) are an important feature of CRUD applications. They can be guaranteed using transactions, ensuring that data stays consistent and operations are \glslink{atomicity}{atomic}. \parencite[10,11]{bernstein_principles_2009}

\subsection{CQRS Architecture}
\label{sec:cqrs}

\acrfull{cqrs} is an architectural pattern based on the fundamental idea that the models used to update information should be separate from the models used to read information. This approach originated as an extension of Bertrand Meyer’s \acrfull{cqs} principle, which states that a method should either perform an action (a command) or return data (a query), but never both. \parencite[148]{meyer_standard_2006}

\acrshort{cqrs} is different from \acrshort{cqs} in the fact that in \acrshort{cqrs}, objects are split into two objects, one containing commands, one containing queries. \parencite[17]{young_cqrs_2010}

\acrshort{cqrs} applications are typically structured by splitting the application into two paths:

\begin{itemize}
    \item Command Side: Deals with data changes and captures user intent. Commands tell the system what needs to be done rather than overwriting previous state. Commands are validated by the system before execution and can be rejected. \parencite[11,12]{young_cqrs_2010}
    \item Read Side: Strictly for reading data. The read side is not allowed to modify anything in the primary data store. The read side typically stores \glspl{dto} in its own data store that can directly be returned to the presentation layer. \parencite[20]{young_cqrs_2010}
\end{itemize}

In a CQRS architecture, the read side typically updates its data asynchronously by consuming notifications or events generated by the write side. Because the models for updating and reading information are strictly separated, a synchronization mechanism is required to ensure the read store eventually reflects the changes made by commands. This usually leads to stale data on the read side.

Each read service independently updates its model by consuming notifications or events published by the write side, allowing the read model to store optimized, denormalized views on the data. \parencite[23]{young_cqrs_2010}

%s TODO figure 

\subsection{(Eventual) Consistency}

% TODO have to talk about "read your writes"? 
% TODO maybe move above CRUD and CQRS 

\textcite{gray_dangers_1996} explain that large-scale systems become unstable if they are held consistent at all times according to \acrshort{acid} principles. This is mostly due to the large amount of communication necessary to handle atomic transactions in distributed systems. To address these issues, modern distributed systems often adopt the \acrshort{base} (\acrlong{base}) model which explicitly trades off isolation and strong consistency for availability. Eventually consistent systems are allowed to exist in a so-called "soft state" which eventually converges through the use of synchronization mechanisms over time rather than being strongly consistent at all times. \parencite{braun_tackling_2021, vogels_eventually_2009} This creates an inconsistency window in which data is not consistent across the system. During this window, stale data may be read. \parencite{vogels_eventually_2009}

\subsection{Event Sourcing and event-driven architectures}
\label{sec:event-sourcing}

Event driven architecture is a design paradigm where systems communicate via the production and consumption of events. Events are records of changes in the system's domain. \parencite{michelson_event-driven_2006} This approach allows for a high degree of loose coupling, as the system publishing an event does not need to know about the recipient(s) or how they will react. These architectures offer excellent horizontal scalability and resilience, as individual system components can fail or be updated without bringing down the entire network. \parencite{fowler_event_2005}

Event Sourcing is an architectural pattern within the landscape of event driven architectures. Event-sourced systems ensure that \emph{all} changes to a system's state are captured and stored as an ordered sequence of domain events. \parencite{fowler_event_2005} Unlike traditional persistence models that overwrite data and store only the most recent state, event sourcing maintains an immutable record of every action taken over time. These events are persisted in an append-only event store, which serves as the principal source of truth from which the current system state can be derived. \parencite{fowler_what_2017,lima_improving_2021} % TODO bessere quelle finden

The current state of any entity in such a system can be rebuilt by replaying the history of events from the log, starting from an initial blank state. \parencite{fowler_event_2005} To address the performance costs of replaying thousands of events for every request, developers implement projections or materialized views, which are read-only, often denormalized versions of the data optimized for specific queries. \parencite{malyi_developing_2024} This separation of concerns is frequently managed by pairing event sourcing with the \hyperref[sec:cqrs]{\acrlong{cqrs} (\acrshort{cqrs})} pattern, which physically divides the data structures used for reading from those used for writing state changes. \parencite[50]{young_cqrs_2010} % TODO Snapshots erklären; Projection = "ephemeral", kann leicht neu gebaut werden 

Because every action taken on the system is stored, a number of facilities can be built on top of the event log: Temporal queries can be made, which determine the exact state of the application at any point in time. The event log acts as an immutable audit trail, making Event Sourcing architectures highly valuable for systems like accounting applications. \parencite{fowler_event_2005}

\subsection{Traceability and auditing in IT systems}

\subsubsection{Audit Logs}

An audit log (often called audit trail) is a chronological record which provides evidence of a sequence of activities on an entity. \parencite{committee_on_national_security_systems_national_2010} In information security, the audit log stores a record of system activities, enabling the reconstruction of events. \parencite{atis_committee_atis_2013} A trustworthy audit log in a system can guarantee the principle of traceability which states that actions can be tracked and traced back to the entity who is responsible for them. \parencite[266]{joint_task_force_interagency_working_group_security_2020}

Traceability and auditing are legal requirements across various sectors, as they are derived from federal laws and regulations intended to protect the integrity and confidentiality of sensitive data. Organizations implement these mechanisms to stay compliant with mandates that require a verifiable, time-sequenced history of system activities to support oversight and forensic reviews. In the financial sector, for example, 17 CFR § 242.613 requires the establishment of a consolidated audit trail to track the complete lifecycle of securities orders, documenting every stage from origination and routing to final execution. \parencite{us_securities_and_exchange_commission_17_2012}

\textcite{fowler_audit_2004} describes an audit log as simple and effective way of storing temporal information. Changes are tracked by writing a record indicating \emph{what} changed \emph{when}. A basic implementation of an audit log can have many forms, for example a text file, database tables or \acrshort{xml} documents. Fowler also mentions that while the audit log is easy to write, it is harder to read and process. While occasional reads can be done by eye, complex processing and reconstruction of historical state can be resource-intensive.

\subsubsection{Event Streams}

\subsubsection{Rebuilding state from an audit log and an event stream}

\subsection{Scalability of systems}

\section{Related Work}

\section{Proposed Method}

This thesis aims to provide a fair, quantitative comparison of \acrshort{crud} and \acrshort{cqrs} / \acrshort{es} architectures. To achieve this, the architectures should be applied not only to the same domain, but to the exact same requirements. The implementations can then be tested against the same \glspl{contract-test}.

This chapter will first present the requirements for the actual application, then outline metrics and comparison methods.

\subsection{Project requirements}

The applications will implement a course enrollment and grading system which might for example be used in universities. Core features include:

\begin{itemize}
    \item Professors can create courses and lectures
    \item Students can enroll and disenroll from lectures
    \item Professors can enter grades
    \item Students can view their current and past lectures
    \item Students can view their credits
\end{itemize}

\subsubsection{Entities}
\label{sec:entities}

Two types of users exist in the domain: professors and students. Their personal information is not relevant for this thesis, which is why only their first and last name are stored for presentation reasons. The student additionally has a semester.

Professors can create courses. Courses have a name, a description, an amount of credits they yield, a minimum amount of credits required to enroll and can have a set of courses as prerequisites.

Courses are the "blueprints" for lectures. Lectures are the "implementation" of a course for a semester. Each lecture created from a course yields the course's amount of credits and has the requirements specified by the course. Lectures have a lifecycle: they can be in draft state, open for enrollment, in progress, finished or archived. A lecture has a list of time slots and a maximum amount of students that can enroll.

A lecture can have several assessments. Each assessment has a type. The professor can enter grades for a student and an assessment. Grades are integers in the range of 0 to 100. Credits are awarded to a student as soon as they completed all assessments for a lecture with a passing grade (grade higher than 50).

\subsubsection{Business rules}

Relationships and business rules in this system are deliberately chosen complex, involving many relationships between \hyperref[sec:entities]{entities} and intricate validation rules. This approach was adopted in order to be able to make realistic assumptions about the research question by evaluating a project that closely resembles complex, real-world scenarios.

\begin{itemize}
    \item Existence checks: any requests including references to entities will fail if the references entities do not exist.
    \item Requests leading to conflicts, for example creating a lecture with overlapping time slots, will fail
    \item When a student tries enrolling to a lecture which is already full, they will be put on a waitlist
    \item When a student disenrolls from a lecture, the next eligible student (higher semesters are preferred) will be enrolled
    \item Actions on a lecture can only be done during the appropriate lifecycle state (enrolling only when the lifecycle is "open for enrollment", grades can only be assigned when the lecture is "finished")
\end{itemize}

\subsubsection{Contract Tests}

To ensure both implementations adhere to the business rules, an extensive test suite was set up. While the internals of the implementations are vastly different architecturally and conceptually, they both have the same public \gls{api}. This makes it possible to run the same test suite on both apps by sending \gls{http} requests and verifying their responses. The test suite includes integration tests for all \gls{api} endpoint covering both regular and edge-case (error) scenarios to ensure that the \acrshort{crud} and \acrshort{es}-\acrshort{cqrs} application exhibit identical state transitions and error behaviors.

\subsection{Performance}

\subsection{Scalability or flexibility (TODO)}

\subsection{Traceability}

\subsection{Tech Stack}

\section{Implementation}

\subsection{Contract Tests}

The contract tests are implemented in a separate maven module called \texttt{test-{\allowbreak}suite}, \footnote{Source code available at /test-suite/src/test/java/karsch.lukas}, where all business rules can be viewed. The test classes use the \texttt{JUnit 5} testing framework and \texttt{REST Assured} to send and assert \gls{http} requests. A basic example might look like this:

\begin{lstlisting}
%%@Test%%
void getLectureDetails_shouldReturn200() {
    // First, create seed data
    var lectureSeedData = createLectureSeedData();

    RestAssured.given()
            .when() 
            .get("/lectures/{lectureId}", lectureSeedData.lectureId())
            .then()
            .statusCode(200)
            .body("data.dates", hasSize(2));
}
\end{lstlisting}

JUnit is an open-source testing framework for Java. It offers a structured way of writing tests, driven by lifecycle methods like \texttt{beforeEach} or \texttt{afterAll}. Tests are annotated with \texttt{@Test}. They can also be parametrized and run repeatedly. Results can be asserted using assertion methods like \texttt{assertTrue()}. \parencite{noauthor_junit_nodate}

REST Assured is a Java library that provides a highly fluent \acrshort{dsl} for testing and validating REST APIs in a readable, chainable style. It allows complex assertions to be written inline using \gls{groovy} expressions, making it easy to deeply verify JSON responses beyond simple field checks. \parencite{haleby_rest_nodate}

The below code example shows how to use a complex expression to find and validate a path in the returned JSON object:

\begin{lstlisting}
RestAssured.when()
// omitted request 
.then()
.body(
    "data.grades.find { it.combinedGrade == 0 }.credits", 
    equalTo(0)
);
\end{lstlisting}

Here, the path \texttt{data.grades} of the returned JSON object is expected to be an array. The array is filtered using a \gls{gpath} with a closure to find the first entry where \texttt{combinedGrade} equals 0. Then, this entry's \texttt{credits} field is extracted and validated using the \texttt{equalTo(0)} matcher.

The test classes in \texttt{test-suite} are all \texttt{abstract}, meaning they can not be run directly. Instead, they are intended to be subclassed by the modules implementing the concrete applications (\texttt{impl-crud} \& \texttt{impl-es-cqrs}). The subclasses must implement a set of abstract methods which are implementation specific, for example a method to reset the database in between each test, a method to set the application's time and methods to create seed data for tests.

Necessary infrastructure is spun up by the subclasses using \glspl{testcontainer}. \glspl{testcontainer} is a way to declare infrastructure dependencies as code and is an open-source library available for many programming languages. \parencite{testcontainers-homepage}

\begin{lstlisting}
%%@TestConfiguration%%(proxyBeanMethods = false)
public class PostgresTestcontainerConfiguration {
    %%@Bean%%
    %%@ServiceConnection%%
    %%@RestartScope%%
    PostgreSQLContainer<?> postgreSQLContainer() {
        return new PostgreSQLContainer<>(
                DockerImageName.parse("postgres:latest")
        );
    }
}
\end{lstlisting}

The above code snippet starts a PostgreSQL container using the latest available image. \texttt{@ServiceConnection} makes sure the Spring application can connect to the container. This configuration can then be imported into the test class:

\begin{lstlisting}
%%@SpringBootTest%%
%%@Import%%(PostgresTestcontainerConfiguration.class)
public class CrudLecturesE2ETest extends AbstractLecturesE2ETest { }
\end{lstlisting}

\subsection{CRUD implementation}

\subsection{ES/CQRS implementation}

\subsection{Infrastructure}

\section{Results}

\section{Discussion}

\subsection{Analysis of results}

\subsection{Conclusion \& Further work}

Finally, I'm done!

\printglossaries

\printbibliography

\appendix

\section{Source Code}

The full source code for this thesis, including both apps, performance tests and markdown notes, is available at: \url{https://gitlab.mi.hdm-stuttgart.de/lk224/thesis}

\end{document} % This is the end of the document
